1
00:00:10,512 --> 00:00:12,418
- Good morning.

2
00:00:12,418 --> 00:00:15,376
So, it's 12:03 so, I want to get started.

3
00:00:15,376 --> 00:00:18,014
Welcome to Lecture 12, of CS-231N.

4
00:00:18,014 --> 00:00:20,180
Today we are going to talk about
Visualizing and Understanding

5
00:00:20,180 --> 00:00:21,840
convolutional networks.

6
00:00:21,840 --> 00:00:23,490
This is always a super fun lecture to give

7
00:00:23,490 --> 00:00:25,270
because we get to look a
lot of pretty pictures.

8
00:00:25,270 --> 00:00:28,375
So, it's, it's one of my favorites.

9
00:00:28,375 --> 00:00:30,354
As usual a couple administrative things.

10
00:00:30,354 --> 00:00:32,743
So, hopefully your projects
are all going well,

11
00:00:32,743 --> 00:00:34,722
because as a reminder your milestones

12
00:00:34,722 --> 00:00:36,595
are due on Canvas tonight.

13
00:00:36,595 --> 00:00:38,057
It is Canvas, right?

14
00:00:38,057 --> 00:00:39,545
Okay, so want to double check, yeah.

15
00:00:39,545 --> 00:00:42,088
Due on Canvas tonight, we are working on

16
00:00:42,088 --> 00:00:43,590
furiously grading your midterms.

17
00:00:43,590 --> 00:00:46,520
So, we'll hope to have those
midterms grades to you back

18
00:00:46,520 --> 00:00:49,537
by on grade scope this week.

19
00:00:49,537 --> 00:00:50,900
So, I know that was little confusion,

20
00:00:50,900 --> 00:00:53,263
you all got registration
email's for grade scope

21
00:00:53,263 --> 00:00:54,988
probably in the last week.

22
00:00:54,988 --> 00:00:57,372
Something like that, we start
couple of questions on piazo.

23
00:00:57,372 --> 00:00:59,530
So, we've decided to use grade
scope to grade the midterms.

24
00:00:59,530 --> 00:01:02,973
So, don't be confused, if you
get some emails about that.

25
00:01:02,973 --> 00:01:05,047
Another reminder is that assignment three

26
00:01:05,047 --> 00:01:07,412
was released last week on Friday.

27
00:01:07,412 --> 00:01:11,088
It will be due, a week from
this Friday, on the 26th.

28
00:01:11,088 --> 00:01:12,595
This is, an assignment three,

29
00:01:12,595 --> 00:01:14,444
is almost entirely brand new this year.

30
00:01:14,444 --> 00:01:17,152
So, it we apologize for taking
a little bit longer than

31
00:01:17,152 --> 00:01:18,847
expected to get it out.

32
00:01:18,847 --> 00:01:20,272
But I think it's super cool.

33
00:01:20,272 --> 00:01:22,644
A lot of that stuff, we'll
talk about in today's lecture.

34
00:01:22,644 --> 00:01:25,283
You'll actually be implementing
on your assignment.

35
00:01:25,283 --> 00:01:27,188
And for the assignment, you'll
get the choice of either

36
00:01:27,188 --> 00:01:29,575
Pi torch or tensure flow.

37
00:01:29,575 --> 00:01:30,921
To work through these different examples.

38
00:01:30,921 --> 00:01:34,512
So, we hope that's really
useful experience for you guys.

39
00:01:34,512 --> 00:01:35,822
We also saw a lot of activity

40
00:01:35,822 --> 00:01:37,273
on HyperQuest over the weekend.

41
00:01:37,273 --> 00:01:39,084
So that's, that's really awesome.

42
00:01:39,084 --> 00:01:40,549
The leader board went up yesterday.

43
00:01:40,549 --> 00:01:42,568
It seems like you guys are
really trying to battle it out

44
00:01:42,568 --> 00:01:44,227
to show off your deep learning

45
00:01:44,227 --> 00:01:46,063
neural network training skills.

46
00:01:46,063 --> 00:01:47,402
So that's super cool.

47
00:01:47,402 --> 00:01:50,087
And we because due to the high interest

48
00:01:50,087 --> 00:01:52,811
in HyperQuest and due to
the conflicts with the,

49
00:01:52,811 --> 00:01:55,118
with the Milestones submission time.

50
00:01:55,118 --> 00:01:56,808
We decided to extend the deadline

51
00:01:56,808 --> 00:01:58,591
for extra credit through Sunday.

52
00:01:58,591 --> 00:02:02,279
So, anyone who does at
least 12 runs on HyperQuest

53
00:02:02,279 --> 00:02:04,773
by Sunday will get little bit
of extra credit in the class.

54
00:02:04,773 --> 00:02:07,394
Also those of you who are,
at the top of leader board

55
00:02:07,394 --> 00:02:09,175
doing really well, will
get may be little bit

56
00:02:09,175 --> 00:02:11,200
extra, extra credit.

57
00:02:11,200 --> 00:02:13,081
So, I thanks for
participating we got lot of

58
00:02:13,081 --> 00:02:15,935
interest and that was really cool.

59
00:02:15,935 --> 00:02:17,844
Final reminder is about
the poster session.

60
00:02:17,844 --> 00:02:21,445
So, we have the poster
session will be on June 6th.

61
00:02:21,445 --> 00:02:22,872
That date is finalized,

62
00:02:22,872 --> 00:02:24,940
I think that, I don't
remember the exact time.

63
00:02:24,940 --> 00:02:25,932
But it is June 6th.

64
00:02:25,932 --> 00:02:27,141
So that, we have some questions

65
00:02:27,141 --> 00:02:29,310
about when exactly that poster session is

66
00:02:29,310 --> 00:02:30,297
for those of you who are traveling

67
00:02:30,297 --> 00:02:31,897
at the end of quarter
or starting internships

68
00:02:31,897 --> 00:02:33,247
or something like that.

69
00:02:33,247 --> 00:02:35,497
So, it will be June 6th.

70
00:02:35,497 --> 00:02:37,210
Any questions on the admin notes.

71
00:02:39,241 --> 00:02:41,171
No, totally clear.

72
00:02:41,171 --> 00:02:42,578
So, last time we talked.

73
00:02:42,578 --> 00:02:44,254
So, last time we had a pretty

74
00:02:44,254 --> 00:02:46,259
jam packed lecture, when we
talked about lot of different

75
00:02:46,259 --> 00:02:48,161
computer vision tasks, as a reminder.

76
00:02:48,161 --> 00:02:49,955
We talked about semantic segmentation

77
00:02:49,955 --> 00:02:52,035
which is this problem, where
you want to sign labels

78
00:02:52,035 --> 00:02:54,318
to every pixel in the input image.

79
00:02:54,318 --> 00:02:56,131
But does not differentiate the

80
00:02:56,131 --> 00:02:58,225
object instances in those images.

81
00:02:58,225 --> 00:03:00,773
We talked about classification
plus localization.

82
00:03:00,773 --> 00:03:02,558
Where in addition to a class label

83
00:03:02,558 --> 00:03:04,059
you also want to draw a box

84
00:03:04,059 --> 00:03:06,539
or perhaps several boxes in the image.

85
00:03:06,539 --> 00:03:08,041
Where the distinction here is that,

86
00:03:08,041 --> 00:03:10,130
in a classification
plus localization setup.

87
00:03:10,130 --> 00:03:12,594
You have some fix number of
objects that you are looking for

88
00:03:12,594 --> 00:03:14,424
So, we also saw that this type of paradigm

89
00:03:14,424 --> 00:03:16,785
can be applied to the things
like pose recognition.

90
00:03:16,785 --> 00:03:18,836
Where you want to regress to
different numbers of joints

91
00:03:18,836 --> 00:03:20,222
in the human body.

92
00:03:20,222 --> 00:03:22,235
We also talked about the object detection

93
00:03:22,235 --> 00:03:23,976
where you start with some fixed

94
00:03:23,976 --> 00:03:25,851
set of category labels
that you are interested in.

95
00:03:25,851 --> 00:03:27,102
Like dogs and cats.

96
00:03:27,102 --> 00:03:29,460
And then the task is
to draw a boxes around

97
00:03:29,460 --> 00:03:31,196
every instance of those objects

98
00:03:31,196 --> 00:03:32,769
that appear in the input image.

99
00:03:32,769 --> 00:03:35,303
And object detection
is really distinct from

100
00:03:35,303 --> 00:03:37,063
classification plus localization

101
00:03:37,063 --> 00:03:38,783
because with object
detection, we don't know

102
00:03:38,783 --> 00:03:40,629
ahead of time, how many object instances

103
00:03:40,629 --> 00:03:42,298
we're looking for in the image.

104
00:03:42,298 --> 00:03:44,272
And we saw that there's
this whole family of methods

105
00:03:44,272 --> 00:03:48,100
based on RCNN, Fast RCNN and faster RCNN,

106
00:03:48,100 --> 00:03:49,916
as well as the single
shot detection methods

107
00:03:49,916 --> 00:03:52,588
for addressing this problem
of object detection.

108
00:03:52,588 --> 00:03:55,026
Then finally we talked
pretty briefly about

109
00:03:55,026 --> 00:03:57,722
instance segmentation,
which is kind of combining

110
00:03:57,722 --> 00:04:01,164
aspects of a semantic
segmentation and object detection

111
00:04:01,164 --> 00:04:03,308
where the goal is to
detect all the instances

112
00:04:03,308 --> 00:04:04,934
of the categories we care about,

113
00:04:04,934 --> 00:04:07,997
as well as label the pixels
belonging to each instance.

114
00:04:07,997 --> 00:04:11,339
So, in this case, we
detected two dogs and one cat

115
00:04:11,339 --> 00:04:13,093
and for each of those instances we wanted

116
00:04:13,093 --> 00:04:14,887
to label all the pixels.

117
00:04:14,887 --> 00:04:17,437
So, these are we kind of
covered a lot last lecture

118
00:04:17,437 --> 00:04:19,509
but those are really interesting
and exciting problems

119
00:04:19,509 --> 00:04:21,284
that you guys might consider to

120
00:04:21,284 --> 00:04:23,810
using in parts of your projects.

121
00:04:23,810 --> 00:04:25,645
But today we are going to
shift gears a little bit

122
00:04:25,645 --> 00:04:27,081
and ask another question.

123
00:04:27,081 --> 00:04:28,702
Which is, what's really going on

124
00:04:28,702 --> 00:04:30,578
inside convolutional networks.

125
00:04:30,578 --> 00:04:32,445
We've seen by this point in the class

126
00:04:32,445 --> 00:04:34,120
how to train convolutional networks.

127
00:04:34,120 --> 00:04:35,916
How to stitch up different
types of architectures

128
00:04:35,916 --> 00:04:37,503
to attack different problems.

129
00:04:37,503 --> 00:04:39,860
But one question that you
might have had in your mind,

130
00:04:39,860 --> 00:04:42,653
is what exactly is going
on inside these networks?

131
00:04:42,653 --> 00:04:44,081
How did they do the things that they do?

132
00:04:44,081 --> 00:04:46,444
What kinds of features
are they looking for?

133
00:04:46,444 --> 00:04:48,612
And all this source of related questions.

134
00:04:48,612 --> 00:04:51,043
So, so far we've sort of seen

135
00:04:51,043 --> 00:04:53,399
ConvNets as a little bit of a black box.

136
00:04:53,399 --> 00:04:55,635
Where some input image of raw pixels

137
00:04:55,635 --> 00:04:57,100
is coming in on one side.

138
00:04:57,100 --> 00:04:58,816
It goes to the many layers of convulsion

139
00:04:58,816 --> 00:05:01,170
and pooling in different
sorts of transformations.

140
00:05:01,170 --> 00:05:04,547
And on the outside, we end up
with some set of class scores

141
00:05:04,547 --> 00:05:07,363
or some types of understandable
interpretable output.

142
00:05:07,363 --> 00:05:09,865
Such as class scores or
bounding box positions

143
00:05:09,865 --> 00:05:12,342
or labeled pixels or something like that.

144
00:05:12,342 --> 00:05:13,307
But the question is.

145
00:05:13,307 --> 00:05:15,933
What are all these other
layers in the middle doing?

146
00:05:15,933 --> 00:05:17,685
What kinds of things in the input image

147
00:05:17,685 --> 00:05:18,567
are they looking for?

148
00:05:18,567 --> 00:05:20,857
And can we try again intuition for.

149
00:05:20,857 --> 00:05:22,023
How ConvNets are working?

150
00:05:22,023 --> 00:05:24,364
What types of things in the
image they are looking for?

151
00:05:24,364 --> 00:05:25,867
And what kinds of techniques do we have

152
00:05:25,867 --> 00:05:29,327
for analyzing this
internals of the network?

153
00:05:29,327 --> 00:05:32,667
So, one relatively simple
thing is the first layer.

154
00:05:32,667 --> 00:05:34,522
So, we've seen, we've
talked about this before.

155
00:05:34,522 --> 00:05:37,508
But recalled that, the
first convolutional layer

156
00:05:37,508 --> 00:05:39,819
consists of a filters that,

157
00:05:39,819 --> 00:05:41,492
so, for example in AlexNet.

158
00:05:41,492 --> 00:05:43,262
The first convolutional layer consists

159
00:05:43,262 --> 00:05:45,193
of a number of convolutional filters.

160
00:05:45,193 --> 00:05:49,230
Each convolutional of filter
has shape 3 by 11 by 11.

161
00:05:49,230 --> 00:05:51,228
And these convolutional filters gets slid

162
00:05:51,228 --> 00:05:52,268
over the input image.

163
00:05:52,268 --> 00:05:54,947
We take inner products between
some chunk of the image.

164
00:05:54,947 --> 00:05:56,909
And the weights of the
convolutional filter.

165
00:05:56,909 --> 00:05:58,689
And that gives us our output of the

166
00:05:58,689 --> 00:06:01,729
at, at after that first
convolutional layer.

167
00:06:01,729 --> 00:06:05,074
So, in AlexNet then we
have 64 of these filters.

168
00:06:05,074 --> 00:06:06,947
But now in the first layer
because we are taking

169
00:06:06,947 --> 00:06:08,780
in a direct inner product
between the weights

170
00:06:08,780 --> 00:06:10,175
of the convolutional layer

171
00:06:10,175 --> 00:06:11,682
and the pixels of the image.

172
00:06:11,682 --> 00:06:14,548
We can get some since for what
these filters are looking for

173
00:06:14,548 --> 00:06:17,697
by simply visualizing the
learned weights of these filters

174
00:06:17,697 --> 00:06:19,458
as images themselves.

175
00:06:19,458 --> 00:06:22,576
So, for each of those
11 by 11 by 3 filters

176
00:06:22,576 --> 00:06:25,027
in AlexNet, we can just
visualize that filter

177
00:06:25,027 --> 00:06:28,461
as a little 11 by 11 image
with a three channels

178
00:06:28,461 --> 00:06:30,201
give you the red, green and blue values.

179
00:06:30,201 --> 00:06:32,051
And then because there
are 64 of these filters

180
00:06:32,051 --> 00:06:35,305
we just visualize 64
little 11 by 11 images.

181
00:06:35,305 --> 00:06:38,047
And we can repeat... So
we have shown here at the.

182
00:06:38,047 --> 00:06:40,982
So, these are filters taken
from the prechain models,

183
00:06:40,982 --> 00:06:42,509
in the pi torch model zoo.

184
00:06:42,509 --> 00:06:44,739
And we are looking at the
convolutional filters.

185
00:06:44,739 --> 00:06:45,985
The weights of the convolutional filters.

186
00:06:45,985 --> 00:06:48,313
at the first layer of AlexNet, ResNet-18,

187
00:06:48,313 --> 00:06:51,065
ResNet-101 and DenseNet-121.

188
00:06:51,065 --> 00:06:53,753
And you can see, kind
of what all these layers

189
00:06:53,753 --> 00:06:55,553
what this filters looking for.

190
00:06:55,553 --> 00:06:59,015
You see the lot of things
looking for oriented edges.

191
00:06:59,015 --> 00:07:01,052
Likes bars of light and dark.

192
00:07:01,052 --> 00:07:04,487
At various angles, in various
angles and various positions

193
00:07:04,487 --> 00:07:07,200
in the input, we can see opposing colors.

194
00:07:07,200 --> 00:07:09,475
Like this are green and pink.

195
00:07:09,475 --> 00:07:12,732
opposing colors or this orange
and blue opposing colors.

196
00:07:12,732 --> 00:07:14,893
So, this, this kind of
connects back to what we

197
00:07:14,893 --> 00:07:16,221
talked about with Hugh and Wiesel.

198
00:07:16,221 --> 00:07:17,907
All the way in the first lecture.

199
00:07:17,907 --> 00:07:19,716
That remember the human visual system

200
00:07:19,716 --> 00:07:22,271
is known to the detect
things like oriented edges.

201
00:07:22,271 --> 00:07:24,978
At the very early layers
of the human visual system.

202
00:07:24,978 --> 00:07:26,946
And it turns out of that
these convolutional networks

203
00:07:26,946 --> 00:07:29,136
tend to do something, somewhat similar.

204
00:07:29,136 --> 00:07:31,566
At their first convolutional
layers as well.

205
00:07:31,566 --> 00:07:33,153
And what's kind of interesting is that

206
00:07:33,153 --> 00:07:35,631
pretty much no matter what type
of architecture you hook up

207
00:07:35,631 --> 00:07:37,920
or whatever type of training
data you are train it on.

208
00:07:37,920 --> 00:07:40,594
You almost always get
the first layers of your.

209
00:07:40,594 --> 00:07:42,736
The first convolutional
weights of any pretty much

210
00:07:42,736 --> 00:07:44,990
any convolutional network
looking at images.

211
00:07:44,990 --> 00:07:46,389
Ends up looking something like this

212
00:07:46,389 --> 00:07:48,676
with oriented edges and opposing colors.

213
00:07:48,676 --> 00:07:51,539
Looking at that input image.

214
00:07:51,539 --> 00:07:53,696
But this really only, sorry
what was that question?

215
00:08:04,215 --> 00:08:06,118
Yes, these are showing the learned weights

216
00:08:06,118 --> 00:08:07,592
of the first convolutional layer.

217
00:08:15,766 --> 00:08:16,826
Oh, so that the question is.

218
00:08:16,826 --> 00:08:18,998
Why does visualizing the
weights of the filters?

219
00:08:18,998 --> 00:08:21,318
Tell you what the filter is looking for.

220
00:08:21,318 --> 00:08:23,945
So this intuition comes from
sort of template matching

221
00:08:23,945 --> 00:08:25,045
and inner products.

222
00:08:25,045 --> 00:08:28,389
That if you imagine you have
some, some template vector.

223
00:08:28,389 --> 00:08:31,125
And then you imagine you
compute a scaler output

224
00:08:31,125 --> 00:08:33,272
by taking inner product
between your template vector

225
00:08:33,272 --> 00:08:35,044
and some arbitrary piece of data.

226
00:08:35,044 --> 00:08:38,321
Then, the input which
maximizes that activation.

227
00:08:38,321 --> 00:08:40,289
Under a norm constraint on the input

228
00:08:40,289 --> 00:08:43,062
is exactly when those
two vectors match up.

229
00:08:43,062 --> 00:08:45,564
So, in that since that,
when, whenever you're taking

230
00:08:45,564 --> 00:08:48,066
inner products, the thing
causes an inner product

231
00:08:48,066 --> 00:08:49,736
to excite maximally

232
00:08:49,736 --> 00:08:52,506
is a copy of the thing you are
taking an inner product with.

233
00:08:52,506 --> 00:08:55,060
So, that, that's why we can
actually visualize these weights

234
00:08:55,060 --> 00:08:56,323
and that, why that shows us,

235
00:08:56,323 --> 00:08:57,902
what this first layer is looking for.

236
00:09:06,008 --> 00:09:08,731
So, for these networks
the first layers always

237
00:09:08,731 --> 00:09:10,052
was a convolutional layer.

238
00:09:10,052 --> 00:09:12,003
So, generally whenever
you are looking at image.

239
00:09:12,003 --> 00:09:13,808
Whenever you are thinking about image data

240
00:09:13,808 --> 00:09:15,174
and training convolutional networks,

241
00:09:15,174 --> 00:09:16,525
you generally put a convolutional layer

242
00:09:16,525 --> 00:09:18,178
at the first, at the first stop.

243
00:09:28,086 --> 00:09:29,006
Yeah, so the question is,

244
00:09:29,006 --> 00:09:30,665
can we do this same type of procedure

245
00:09:30,665 --> 00:09:32,118
in the middle open network.

246
00:09:32,118 --> 00:09:33,202
That's actually the next slide.

247
00:09:33,202 --> 00:09:35,104
So, good anticipation.

248
00:09:35,104 --> 00:09:37,123
So, if we do, if we draw this exact same

249
00:09:37,123 --> 00:09:39,767
visualization for the
intermediate convolutional layers.

250
00:09:39,767 --> 00:09:41,753
It's actually a lot less interpretable.

251
00:09:41,753 --> 00:09:45,081
So, this is, this is performing
exact same visualization.

252
00:09:45,081 --> 00:09:49,278
So, remember for this using
the tiny ConvNets demo network

253
00:09:49,278 --> 00:09:50,474
that's running on the course website

254
00:09:50,474 --> 00:09:51,890
whenever you go there.

255
00:09:51,890 --> 00:09:52,702
So, for that network,

256
00:09:52,702 --> 00:09:55,987
the first layer is 7 by
7 convulsion 16 filters.

257
00:09:55,987 --> 00:09:58,263
So, after the top visualizing
the first layer weights

258
00:09:58,263 --> 00:10:00,842
for this network just like
we saw in a previous slide.

259
00:10:00,842 --> 00:10:02,366
But now at the second layer weights.

260
00:10:02,366 --> 00:10:04,491
After we do a convulsion
then there's some relu

261
00:10:04,491 --> 00:10:06,583
and some other non-linearity perhaps.

262
00:10:06,583 --> 00:10:08,185
But the second convolutional layer,

263
00:10:08,185 --> 00:10:10,629
now receives the 16 channel input.

264
00:10:10,629 --> 00:10:15,116
And does 7 by 7 convulsion
with 20 convolutional filters.

265
00:10:15,116 --> 00:10:16,064
And we've actually,

266
00:10:16,064 --> 00:10:18,660
so the problem is that
you can't really visualize

267
00:10:18,660 --> 00:10:20,495
these directly as images.

268
00:10:20,495 --> 00:10:23,846
So, you can try, so, here if you

269
00:10:23,846 --> 00:10:28,547
this 16 by, so the input is
this has 16 dimensions in depth.

270
00:10:28,547 --> 00:10:30,286
And we have these convolutional filters,

271
00:10:30,286 --> 00:10:32,542
each convolutional filter is 7 by 7,

272
00:10:32,542 --> 00:10:34,388
and is extending along the full depth

273
00:10:34,388 --> 00:10:35,759
so has 16 elements.

274
00:10:35,759 --> 00:10:38,072
Then we've 20 such of these
convolutional filters,

275
00:10:38,072 --> 00:10:40,924
that are producing the output
planes of the next layer.

276
00:10:40,924 --> 00:10:44,035
But the problem here is that
we can't, looking at the,

277
00:10:44,035 --> 00:10:45,128
looking directly at the weights

278
00:10:45,128 --> 00:10:47,498
of these filters, doesn't
really tell us much.

279
00:10:47,498 --> 00:10:49,734
So, we, that's really done here is that,

280
00:10:49,734 --> 00:10:53,743
now for this single 16 by 7
by 7 convolutional filter.

281
00:10:53,743 --> 00:10:58,192
We can spread out those 167
by 7 planes of the filter

282
00:10:58,192 --> 00:11:01,782
into a 167 by 7 grayscale images.

283
00:11:01,782 --> 00:11:03,284
So, that's what we've done.

284
00:11:03,284 --> 00:11:07,095
Up here, which is these little
tiny gray scale images here

285
00:11:07,095 --> 00:11:08,898
show us what is, what are the weights

286
00:11:08,898 --> 00:11:11,852
in one of the convolutional
filters of the second layer.

287
00:11:11,852 --> 00:11:14,473
And now, because there are
20 outputs from this layer.

288
00:11:14,473 --> 00:11:17,534
Then this second convolutional
layer, has 2o such of these

289
00:11:17,534 --> 00:11:21,046
16 by 16 or 16 by 7 by 7 filters.

290
00:11:21,046 --> 00:11:22,871
So if we visualize the weights

291
00:11:22,871 --> 00:11:24,307
of those convolutional filters

292
00:11:24,307 --> 00:11:26,709
as images, you can see that there are some

293
00:11:26,709 --> 00:11:28,638
kind of spacial structures here.

294
00:11:28,638 --> 00:11:30,897
But it doesn't really
give you good intuition

295
00:11:30,897 --> 00:11:32,128
for what they are looking at.

296
00:11:32,128 --> 00:11:35,099
Because these filters are not
looking, are not connected

297
00:11:35,099 --> 00:11:36,644
directly to the input image.

298
00:11:36,644 --> 00:11:39,493
Instead recall that the second
layer convolutional filters

299
00:11:39,493 --> 00:11:41,851
are connected to the
output of the first layer.

300
00:11:41,851 --> 00:11:44,189
So, this is giving visualization of,

301
00:11:44,189 --> 00:11:46,684
what type of activation
pattern after the first

302
00:11:46,684 --> 00:11:49,331
convulsion, would cause
the second layer convulsion

303
00:11:49,331 --> 00:11:50,646
to maximally activate.

304
00:11:50,646 --> 00:11:52,423
But, that's not very interpretable

305
00:11:52,423 --> 00:11:53,860
because we don't have a good sense

306
00:11:53,860 --> 00:11:55,966
for what those first layer
convulsions look like

307
00:11:55,966 --> 00:11:58,490
in terms of image pixels.

308
00:11:58,490 --> 00:12:00,893
So we'll need to develop some
slightly more fancy technique

309
00:12:00,893 --> 00:12:02,047
to get a sense for what is going on

310
00:12:02,047 --> 00:12:03,556
in the intermediate layers.

311
00:12:03,556 --> 00:12:04,819
Question in the back.

312
00:12:09,189 --> 00:12:10,489
Yeah. So the question is that

313
00:12:10,489 --> 00:12:13,456
for... all the visualization
on this on the previous slide.

314
00:12:13,456 --> 00:12:16,552
We've had the scale the weights
to the zero to 255 range.

315
00:12:16,552 --> 00:12:18,648
So in practice those
weights could be unbounded.

316
00:12:18,648 --> 00:12:19,885
They could have any range.

317
00:12:19,885 --> 00:12:22,983
But to get nice visualizations
we need to scale those.

318
00:12:22,983 --> 00:12:24,685
These visualizations also do not take

319
00:12:24,685 --> 00:12:26,409
in to account the bias is in these layers.

320
00:12:26,409 --> 00:12:28,162
So you should keep that in mind

321
00:12:28,162 --> 00:12:30,423
when and not take these
HEPS visualizations

322
00:12:30,423 --> 00:12:31,892
to, to literally.

323
00:12:34,180 --> 00:12:35,237
Now at the last layer

324
00:12:35,237 --> 00:12:36,733
remember when we looking at the last layer

325
00:12:36,733 --> 00:12:38,391
of convolutional network.

326
00:12:38,391 --> 00:12:40,698
We have these maybe 1000 class scores

327
00:12:40,698 --> 00:12:42,891
that are telling us what
are the predicted scores

328
00:12:42,891 --> 00:12:44,908
for each of the classes
in our training data set

329
00:12:44,908 --> 00:12:46,676
and immediately before the last layer

330
00:12:46,676 --> 00:12:48,628
we often have some fully connected layer.

331
00:12:48,628 --> 00:12:49,962
In the case of Alex net

332
00:12:49,962 --> 00:12:53,039
we have some 4096- dimensional
features representation

333
00:12:53,039 --> 00:12:55,516
of our image that then
gets fed into that final

334
00:12:55,516 --> 00:12:58,328
our final layer to predict
our final class scores.

335
00:12:58,328 --> 00:13:00,606
And one another, another kind of route

336
00:13:00,606 --> 00:13:02,787
for tackling the problem
of visual, visualizing

337
00:13:02,787 --> 00:13:04,263
and understanding ConvNets

338
00:13:04,263 --> 00:13:06,520
is to try to understand what's
happening at the last layer

339
00:13:06,520 --> 00:13:07,967
of a convolutional network.

340
00:13:07,967 --> 00:13:09,022
So what we can do

341
00:13:09,022 --> 00:13:11,230
is how to take some,
some data set of images

342
00:13:11,230 --> 00:13:13,110
run a bunch of, run a bunch of images

343
00:13:13,110 --> 00:13:14,815
through our trained convolutional network

344
00:13:14,815 --> 00:13:17,174
and recorded that 4096 dimensional vector

345
00:13:17,174 --> 00:13:18,687
for each of those images.

346
00:13:18,687 --> 00:13:20,722
And now go through and try to figure out

347
00:13:20,722 --> 00:13:23,219
and visualize that last
layer, that last hidden layer

348
00:13:23,219 --> 00:13:26,075
rather than those rather than
the first convolutional layer.

349
00:13:26,075 --> 00:13:27,804
So, one thing you might imagine is,

350
00:13:27,804 --> 00:13:29,791
is trying a nearest neighbor approach.

351
00:13:29,791 --> 00:13:31,559
So, remember, way back
in the second lecture

352
00:13:31,559 --> 00:13:33,162
we saw this graphic on the left

353
00:13:33,162 --> 00:13:36,045
where we, where we had a
nearest neighbor classifier.

354
00:13:36,045 --> 00:13:37,967
Where we were looking at
nearest neighbors in pixels

355
00:13:37,967 --> 00:13:40,303
space between CIFAR 10 images.

356
00:13:40,303 --> 00:13:41,996
And then when you look
at nearest neighbors

357
00:13:41,996 --> 00:13:44,765
in pixel space between CIFAR 10 images

358
00:13:44,765 --> 00:13:46,500
you see that you pull up images

359
00:13:46,500 --> 00:13:48,660
that looks quite similar
to the query image.

360
00:13:48,660 --> 00:13:50,777
So again on the left column
here is some CIFAR 10 image

361
00:13:50,777 --> 00:13:52,350
from the CIFAR 10 data set

362
00:13:52,350 --> 00:13:54,987
and then these, these next five columns

363
00:13:54,987 --> 00:13:57,239
are showing the nearest
neighbors in pixel space

364
00:13:57,239 --> 00:13:58,917
to those test set images.

365
00:13:58,917 --> 00:14:00,185
And so for example

366
00:14:00,185 --> 00:14:02,446
this white dog that you see here,

367
00:14:02,446 --> 00:14:04,523
it's nearest neighbors are in pixel space

368
00:14:04,523 --> 00:14:06,328
are these kinds of white blobby things

369
00:14:06,328 --> 00:14:08,321
that may, may or may not be dogs,

370
00:14:08,321 --> 00:14:09,885
but at least the raw pixels

371
00:14:09,885 --> 00:14:11,643
of the image are quite similar.

372
00:14:11,643 --> 00:14:14,268
So now we can do the same
type of visualization

373
00:14:14,268 --> 00:14:16,937
computing and visualizing
these nearest neighbor images.

374
00:14:16,937 --> 00:14:17,963
But rather than computing

375
00:14:17,963 --> 00:14:19,952
the nearest neighbors in pixel space,

376
00:14:19,952 --> 00:14:21,735
instead we can compute nearest neighbors

377
00:14:21,735 --> 00:14:24,507
in that 4096 dimensional feature space.

378
00:14:24,507 --> 00:14:27,107
Which is computed by the
convolutional network.

379
00:14:27,107 --> 00:14:28,351
So here on the right

380
00:14:28,351 --> 00:14:29,987
we see some examples.

381
00:14:29,987 --> 00:14:32,069
So this, this first column shows us

382
00:14:32,069 --> 00:14:34,924
some examples of images from the test set

383
00:14:34,924 --> 00:14:38,338
of image that... Of the image
net classification data set

384
00:14:38,338 --> 00:14:41,253
and now the, these
subsequent columns show us

385
00:14:41,253 --> 00:14:43,614
nearest neighbors to those test set images

386
00:14:43,614 --> 00:14:46,863
in the 4096, in the 4096th
dimensional features space

387
00:14:46,863 --> 00:14:48,515
computed by Alex net.

388
00:14:48,515 --> 00:14:51,010
And you can see here that
this is quite different

389
00:14:51,010 --> 00:14:52,941
from the pixel space nearest neighbors,

390
00:14:52,941 --> 00:14:55,086
because the pixels are
often quite different.

391
00:14:55,086 --> 00:14:57,111
between the image in
it's nearest neighbors

392
00:14:57,111 --> 00:14:58,375
and feature space.

393
00:14:58,375 --> 00:15:00,751
However, the semantic
content of those images

394
00:15:00,751 --> 00:15:03,031
tends to be similar in this feature space.

395
00:15:03,031 --> 00:15:05,612
So for example, if you
look at this second layer

396
00:15:05,612 --> 00:15:07,243
the query image is this elephant

397
00:15:07,243 --> 00:15:08,523
standing on the left side of the image

398
00:15:08,523 --> 00:15:10,484
with a screen grass behind him.

399
00:15:10,484 --> 00:15:12,521
and now one of these, one of these...

400
00:15:12,521 --> 00:15:14,542
it's third nearest
neighbor in the tough set

401
00:15:14,542 --> 00:15:15,818
is actually an elephant standing

402
00:15:15,818 --> 00:15:17,307
on the right side of the image.

403
00:15:17,307 --> 00:15:18,719
So this is really interesting.

404
00:15:18,719 --> 00:15:21,308
Because between this
elephant standing on the left

405
00:15:21,308 --> 00:15:23,640
and this element stand,
elephant standing on the right

406
00:15:23,640 --> 00:15:25,382
the pixels between those two images

407
00:15:25,382 --> 00:15:26,942
are almost entirely different.

408
00:15:26,942 --> 00:15:28,534
However, in the feature space

409
00:15:28,534 --> 00:15:29,967
which is learned by the network

410
00:15:29,967 --> 00:15:32,554
those two images and that
being very close to each other.

411
00:15:32,554 --> 00:15:35,138
Which means that somehow
this, this last their features

412
00:15:35,138 --> 00:15:37,975
is capturing some of those
semantic content of these images.

413
00:15:37,975 --> 00:15:39,953
That's really cool and really exciting

414
00:15:39,953 --> 00:15:40,955
and, and in general looking

415
00:15:40,955 --> 00:15:42,822
at these kind of nearest
neighbor visualizations

416
00:15:42,822 --> 00:15:44,625
is really quick and easy way to visualize

417
00:15:44,625 --> 00:15:46,192
something about what's going on here.

418
00:16:02,617 --> 00:16:04,630
Yes. So the question is that

419
00:16:04,630 --> 00:16:07,598
through the... the standard
supervised learning procedure

420
00:16:07,598 --> 00:16:09,902
for classific training,
classification network

421
00:16:09,902 --> 00:16:11,046
There's nothing in the loss

422
00:16:11,046 --> 00:16:13,942
encouraging these features
to be close together.

423
00:16:13,942 --> 00:16:15,072
So that, that's true.

424
00:16:15,072 --> 00:16:16,477
It just kind of a happy accident

425
00:16:16,477 --> 00:16:18,033
that they end up being
close to each other.

426
00:16:18,033 --> 00:16:19,800
Because we didn't tell the
network during training

427
00:16:19,800 --> 00:16:21,476
these features should be close.

428
00:16:21,476 --> 00:16:24,364
However there are sometimes
people do train networks

429
00:16:24,364 --> 00:16:27,499
using things called
either contrastive loss

430
00:16:27,499 --> 00:16:28,746
or a triplet loss.

431
00:16:28,746 --> 00:16:31,395
Which actually explicitly make...

432
00:16:31,395 --> 00:16:33,287
assumptions and constraints on the network

433
00:16:33,287 --> 00:16:34,792
such that those last their features

434
00:16:34,792 --> 00:16:37,253
end up having some metric
space interpretation.

435
00:16:37,253 --> 00:16:39,907
But Alex net at least was not
trained specifically for that.

436
00:16:44,931 --> 00:16:46,060
The question is, what is the nearest...

437
00:16:46,060 --> 00:16:47,434
What is this nearest neighbor thing

438
00:16:47,434 --> 00:16:48,875
have to do at the last layer?

439
00:16:48,875 --> 00:16:50,120
So we're taking this image

440
00:16:50,120 --> 00:16:51,432
we're running it through the network

441
00:16:51,432 --> 00:16:53,560
and then the, the second to last

442
00:16:53,560 --> 00:16:55,888
like the last hidden layer of the network

443
00:16:55,888 --> 00:16:57,670
is of 4096th dimensional vector.

444
00:16:57,670 --> 00:16:58,791
Because there's this, this is...

445
00:16:58,791 --> 00:17:00,681
This is there, there are
these fully connected layers

446
00:17:00,681 --> 00:17:01,797
at the end of the network.

447
00:17:01,797 --> 00:17:03,096
So we are doing is...

448
00:17:03,096 --> 00:17:05,619
We're writing down that
4096th dimensional vector

449
00:17:05,619 --> 00:17:06,893
for each of the images

450
00:17:06,894 --> 00:17:08,382
and then we are computing
nearest neighbors

451
00:17:08,382 --> 00:17:10,922
according to that 4096th
dimensional vector.

452
00:17:10,922 --> 00:17:12,966
Which is computed by,
computed by the network.

453
00:17:17,012 --> 00:17:19,171
Maybe, maybe we can chat offline.

454
00:17:19,171 --> 00:17:21,048
So another, another, another

455
00:17:21,048 --> 00:17:22,397
another angle that we might have

456
00:17:22,397 --> 00:17:24,988
for visualizing what's
going on in this last layer

457
00:17:24,989 --> 00:17:28,435
is by some concept of
dimensionality reduction.

458
00:17:28,435 --> 00:17:31,220
So those of you who have
taken CS229 for example

459
00:17:31,220 --> 00:17:33,220
you've seen something like PCA.

460
00:17:33,220 --> 00:17:35,561
Which let's you take some high
dimensional representation

461
00:17:35,561 --> 00:17:37,710
like these 4096th dimensional features

462
00:17:37,710 --> 00:17:39,841
and then compress it
down to two-dimensions.

463
00:17:39,841 --> 00:17:43,183
So then you can visualize that
feature space more directly.

464
00:17:43,183 --> 00:17:45,631
So, Principle Component Analysis or PCA

465
00:17:45,631 --> 00:17:47,203
is kind of one way to do that.

466
00:17:47,203 --> 00:17:50,227
But there's real another
really powerful algorithm

467
00:17:50,227 --> 00:17:51,321
called t-SNE.

468
00:17:51,321 --> 00:17:54,656
Standing for t-distributed
stochastic neighbor embeddings.

469
00:17:54,656 --> 00:17:57,042
Which is slightly more powerful method.

470
00:17:57,042 --> 00:17:59,746
Which is a non-linear
dimensionality reduction method

471
00:17:59,746 --> 00:18:03,137
that people in deep often
use for visualizing features.

472
00:18:03,137 --> 00:18:07,264
So here as an, just an
example of what t-SNE can do.

473
00:18:07,264 --> 00:18:09,363
This visualization here is, is showing

474
00:18:09,363 --> 00:18:13,231
a t-SNE dimensionality reduction
on the emnest data set.

475
00:18:13,231 --> 00:18:15,118
So, emnest remember is this date set

476
00:18:15,118 --> 00:18:17,521
of hand written digits
between zero and nine.

477
00:18:17,521 --> 00:18:19,484
Each image is a gray scale image

478
00:18:19,484 --> 00:18:22,226
20... 28 by 28 gray scale image

479
00:18:22,226 --> 00:18:23,954
and now we're... So that

480
00:18:23,954 --> 00:18:25,268
Now we've, we've used t-SNE

481
00:18:25,268 --> 00:18:28,336
to take that 28 times 28
dimensional features space

482
00:18:28,336 --> 00:18:29,901
of the raw pixels for m-nest

483
00:18:29,901 --> 00:18:32,020
and now compress it
down to two- dimensions

484
00:18:32,020 --> 00:18:34,275
ans then visualize each
of those m-nest digits

485
00:18:34,275 --> 00:18:37,096
in this compress
two-dimensional representation

486
00:18:37,096 --> 00:18:38,711
and when you do, when you run t-SNE

487
00:18:38,711 --> 00:18:40,596
on the raw pixels and m-nest

488
00:18:40,596 --> 00:18:42,653
You can see these natural
clusters appearing.

489
00:18:42,653 --> 00:18:45,373
Which corresponds to the,
the digits of these m-nest

490
00:18:45,373 --> 00:18:47,532
of, of these m-nest data set.

491
00:18:47,532 --> 00:18:49,764
So now we can do a similar
type of visualization.

492
00:18:49,764 --> 00:18:52,994
Where we apply this t-SNE
dimensionality reduction technique

493
00:18:52,994 --> 00:18:55,007
to the features from the last layer

494
00:18:55,007 --> 00:18:57,348
of our trained image net classifier.

495
00:18:57,348 --> 00:18:59,544
So...To be a little bit more concrete here

496
00:18:59,544 --> 00:19:00,369
what we've done

497
00:19:00,369 --> 00:19:03,087
is that we take, a large set of images

498
00:19:03,087 --> 00:19:05,073
we run them off convolutional network.

499
00:19:05,073 --> 00:19:08,187
We record that final 4096th
dimensional feature vector

500
00:19:08,187 --> 00:19:10,865
for, from the last layer
of each of those images.

501
00:19:10,865 --> 00:19:12,437
Which gives us large collection

502
00:19:12,437 --> 00:19:14,756
of 4096th dimensional vectors.

503
00:19:14,756 --> 00:19:17,509
Now we apply t-SNE
dimensionality reduction

504
00:19:17,509 --> 00:19:20,848
to compute, sort of compress
that 4096the dimensional

505
00:19:20,848 --> 00:19:24,277
features space down into a
two-dimensional feature space

506
00:19:24,277 --> 00:19:27,454
and now we, layout a grid in that

507
00:19:27,454 --> 00:19:29,778
compressed two-dimensional feature space

508
00:19:29,778 --> 00:19:32,391
and visualize what types of images appear

509
00:19:32,391 --> 00:19:34,115
at each location in the grid

510
00:19:34,115 --> 00:19:36,415
in this two-dimensional feature space.

511
00:19:36,415 --> 00:19:39,454
So by doing this you get
some very close rough sense

512
00:19:39,454 --> 00:19:41,196
of what the geometry

513
00:19:41,196 --> 00:19:43,417
of this learned feature space looks like.

514
00:19:43,417 --> 00:19:45,426
So these images are
little bit hard to see.

515
00:19:45,426 --> 00:19:46,504
So I'd encourage you to check out

516
00:19:46,504 --> 00:19:48,620
the high resolution versions online.

517
00:19:48,620 --> 00:19:51,409
But at least maybe on
the left you can see that

518
00:19:51,409 --> 00:19:53,398
there's sort of one
cluster in the bottom here

519
00:19:53,398 --> 00:19:56,451
of, of green things, is a
different kind of flowers

520
00:19:56,451 --> 00:19:57,855
and there's other types of clusters

521
00:19:57,855 --> 00:19:59,374
for different types of dog breeds

522
00:19:59,374 --> 00:20:01,800
and another types of
animals and, and locations.

523
00:20:01,800 --> 00:20:05,020
So there's sort of
discontinuous semantic notion

524
00:20:05,020 --> 00:20:06,192
in this feature space.

525
00:20:06,192 --> 00:20:08,123
Which we can explore by looking through

526
00:20:08,123 --> 00:20:10,080
this t-SNE dimensionality reduction

527
00:20:10,080 --> 00:20:11,597
version of the, of the features.

528
00:20:11,597 --> 00:20:12,604
Is there question?

529
00:20:23,716 --> 00:20:25,849
Yeah. So the basic idea is that we're

530
00:20:25,849 --> 00:20:26,887
we, we have an image

531
00:20:26,887 --> 00:20:28,599
so now we end up with
three different pieces

532
00:20:28,599 --> 00:20:29,793
of information about each image.

533
00:20:29,793 --> 00:20:31,308
We have the pixels of the image.

534
00:20:31,308 --> 00:20:33,353
We have the 4096th dimensional vector.

535
00:20:33,353 --> 00:20:36,312
Then we use t-SNE to convert
the 4096th dimensional vector

536
00:20:36,312 --> 00:20:38,109
into a two-dimensional coordinate

537
00:20:38,109 --> 00:20:40,430
and then we take the
original pixels of the image

538
00:20:40,430 --> 00:20:42,511
and place that at the
two-dimensional coordinate

539
00:20:42,511 --> 00:20:44,532
corresponding to the
dimensionality reduced version

540
00:20:44,532 --> 00:20:48,090
of the 4096th dimensional feature.

541
00:20:48,090 --> 00:20:49,547
Yeah, little bit involved here.

542
00:20:49,547 --> 00:20:50,348
Question in the front.

543
00:20:55,864 --> 00:20:56,459
The question is

544
00:20:56,459 --> 00:20:59,255
Roughly how much variants do
these two-dimension explain?

545
00:20:59,255 --> 00:21:00,993
Well, I'm not sure of the exact number

546
00:21:00,993 --> 00:21:02,185
and I get little bit muddy

547
00:21:02,185 --> 00:21:03,550
when you're talking about t-SNE,

548
00:21:03,550 --> 00:21:04,555
because it's a non-linear

549
00:21:04,555 --> 00:21:06,080
dimensionality reduction technique.

550
00:21:06,080 --> 00:21:07,668
So, I'd have to look offline

551
00:21:07,668 --> 00:21:10,259
and I'm not sure of exactly
how much it explains.

552
00:21:10,259 --> 00:21:14,377
Question?

553
00:21:14,377 --> 00:21:16,143
Question is, can you do the same analysis

554
00:21:16,143 --> 00:21:17,038
of upper layers of the network?

555
00:21:17,038 --> 00:21:18,358
And yes, you can. But no,

556
00:21:18,358 --> 00:21:21,384
I don't have those
visualizations here. Sorry.

557
00:21:21,384 --> 00:21:24,603
Question?

558
00:21:35,559 --> 00:21:37,434
The question is,
Shouldn't we have overlaps

559
00:21:37,434 --> 00:21:39,482
of images once we do this
dimensionality reduction?

560
00:21:39,482 --> 00:21:40,902
And yes, of course, you would.

561
00:21:40,902 --> 00:21:43,118
So this is just kind of taking a,

562
00:21:43,118 --> 00:21:45,119
nearest neighbor in
our, in our regular grid

563
00:21:45,119 --> 00:21:47,537
and then picking an image
close to that grid point.

564
00:21:47,537 --> 00:21:49,397
So, so... they, yeah.

565
00:21:49,397 --> 00:21:52,875
this is not showing
you the kind of density

566
00:21:52,875 --> 00:21:54,792
in different parts of the feature space.

567
00:21:54,792 --> 00:21:56,985
So that's, that's another thing to look at

568
00:21:56,985 --> 00:21:58,753
and again at the link
you, there's a couple more

569
00:21:58,753 --> 00:22:00,584
visualizations of this nature that,

570
00:22:00,584 --> 00:22:03,122
that address that a little bit.

571
00:22:03,122 --> 00:22:04,779
Okay. So another, another thing

572
00:22:04,779 --> 00:22:07,713
that you can do for some of
these intermediate features

573
00:22:07,713 --> 00:22:09,656
is, so we talked a couple of slides ago

574
00:22:09,656 --> 00:22:12,157
that visualizing the weights
of these intermediate layers

575
00:22:12,157 --> 00:22:13,856
is not so interpretable.

576
00:22:13,856 --> 00:22:17,260
But actually visualizing
the activation maps of those

577
00:22:17,260 --> 00:22:18,430
intermediate layers

578
00:22:18,430 --> 00:22:20,846
is kind of interpretable in some cases.

579
00:22:20,846 --> 00:22:24,152
So for, so I, again an
example of Alex Net.

580
00:22:24,152 --> 00:22:26,777
Remember the, the conv5
layers of Alex Net.

581
00:22:26,777 --> 00:22:28,603
Gives us this 128 by...

582
00:22:28,603 --> 00:22:31,640
The for...The conv5 features for any image

583
00:22:31,640 --> 00:22:35,668
is now 128 by 13 by 13 dimensional tensor.

584
00:22:35,668 --> 00:22:36,998
But we can think of that

585
00:22:36,998 --> 00:22:39,799
as 128 different

586
00:22:39,799 --> 00:22:42,386
13 by 132-D grids.

587
00:22:42,386 --> 00:22:44,347
So now we can actually go and visualize

588
00:22:44,347 --> 00:22:47,285
each of those 13 by 13 elements slices

589
00:22:47,285 --> 00:22:49,741
of the feature map as a grayscale image

590
00:22:49,741 --> 00:22:52,733
and this gives us some sense
for what types of things

591
00:22:52,733 --> 00:22:55,759
in the input are each of those features

592
00:22:55,759 --> 00:22:58,501
in that convolutional layer looking for.

593
00:22:58,501 --> 00:23:00,621
So this is a, a really
cool interactive tool

594
00:23:00,621 --> 00:23:03,306
by Jason Yasenski you can just download.

595
00:23:03,306 --> 00:23:05,137
So it's run, so I don't have the video,

596
00:23:05,137 --> 00:23:06,598
it has a video on his website.

597
00:23:06,598 --> 00:23:08,349
But it's running a convolutional network

598
00:23:08,349 --> 00:23:10,059
on the inputs stream of webcam

599
00:23:10,059 --> 00:23:12,213
and then visualizing in real time

600
00:23:12,213 --> 00:23:15,348
each of those slices of that
intermediate feature map

601
00:23:15,348 --> 00:23:17,279
give you a sense of what it's looking for

602
00:23:17,279 --> 00:23:19,328
and you can see that,
so here the input image

603
00:23:19,328 --> 00:23:21,509
is this, this picture up in, settings...

604
00:23:21,509 --> 00:23:23,931
of this picture of a person
in front of the camera

605
00:23:23,931 --> 00:23:26,026
and most of these intermediate features

606
00:23:26,026 --> 00:23:28,192
are kind of noisy, not much going on.

607
00:23:28,192 --> 00:23:30,190
But there's a, but there's
this one highlighted

608
00:23:30,190 --> 00:23:31,527
intermediate feature

609
00:23:31,527 --> 00:23:34,277
where that is also shown larger here

610
00:23:34,277 --> 00:23:35,911
that seems that it's activating

611
00:23:35,911 --> 00:23:37,827
on the portions of the feature map

612
00:23:37,827 --> 00:23:39,815
corresponding to the person's face.

613
00:23:39,815 --> 00:23:41,103
Which is really interesting

614
00:23:41,103 --> 00:23:43,719
and that kind of,
suggests that maybe this,

615
00:23:43,719 --> 00:23:45,863
this particular slice of the feature map

616
00:23:45,863 --> 00:23:47,896
of this layer of this particular network

617
00:23:47,896 --> 00:23:51,045
is maybe looking for human
faces or something like that.

618
00:23:51,045 --> 00:23:53,036
Which is kind of a nice, kind of a nice

619
00:23:53,036 --> 00:23:54,132
and cool finding.

620
00:23:54,132 --> 00:23:55,517
Question?

621
00:23:59,038 --> 00:24:02,649
The question is, Are the
black activations dead relu's?

622
00:24:02,649 --> 00:24:04,957
So you got to be... a little
careful with terminology.

623
00:24:04,957 --> 00:24:07,043
We usually say dead relu to mean

624
00:24:07,043 --> 00:24:09,539
something that's dead over
the entire training data set.

625
00:24:09,539 --> 00:24:12,571
Here I would say that it's a
relu, that, it's not active

626
00:24:12,571 --> 00:24:14,701
for this particular input.

627
00:24:14,701 --> 00:24:15,702
Question?

628
00:24:19,457 --> 00:24:21,338
The question is, If there's
no humans in image net

629
00:24:21,338 --> 00:24:22,538
how can it recognize a human face?

630
00:24:22,538 --> 00:24:24,182
There definitely are humans in image net

631
00:24:24,182 --> 00:24:26,033
I don't think it's, it's one of the cat...

632
00:24:26,033 --> 00:24:27,793
I don't think it's one of
the thousand categories

633
00:24:27,793 --> 00:24:29,020
for the classification challenge.

634
00:24:29,020 --> 00:24:31,068
But people definitely appear
in a lot of these images

635
00:24:31,068 --> 00:24:32,684
and that can be useful
signal for detecting

636
00:24:32,684 --> 00:24:34,906
other types of things.

637
00:24:34,906 --> 00:24:36,698
So that's actually kind of nice results

638
00:24:36,698 --> 00:24:39,148
because that shows that, it's
sort of can learn features

639
00:24:39,148 --> 00:24:41,617
that are useful for the
classification task at hand.

640
00:24:41,617 --> 00:24:42,977
That are even maybe a little bit different

641
00:24:42,977 --> 00:24:44,516
from the explicit classification task

642
00:24:44,516 --> 00:24:45,792
that we told it to perform.

643
00:24:45,792 --> 00:24:47,483
So it's actually really cool results.

644
00:24:50,346 --> 00:24:51,929
Okay, question?

645
00:24:55,192 --> 00:24:57,147
So at each layer in the
convolutional network

646
00:24:57,147 --> 00:25:01,171
our input image is of three,
it's like 3 by 224 by 224

647
00:25:01,171 --> 00:25:03,334
and then it goes through
many stages of convolution.

648
00:25:03,334 --> 00:25:05,428
And then, it, after
each convolutional layer

649
00:25:05,428 --> 00:25:07,731
is some three dimensional
chunk of numbers.

650
00:25:07,731 --> 00:25:09,157
Which are the outputs from that layer

651
00:25:09,157 --> 00:25:10,476
of the convolutional network.

652
00:25:10,476 --> 00:25:13,651
And that into the entire three
dimensional chunk of numbers

653
00:25:13,651 --> 00:25:15,648
which are the output of the
previous convolutional layer,

654
00:25:15,648 --> 00:25:18,155
we call, we call, like
an activation volume

655
00:25:18,155 --> 00:25:20,235
and then one of those, one of those slices

656
00:25:20,235 --> 00:25:22,156
is a, it's an activation map.

657
00:25:34,426 --> 00:25:36,458
So the question is, If the image is K by K

658
00:25:36,458 --> 00:25:38,513
will the activation map be K by K?

659
00:25:38,513 --> 00:25:40,375
Not always because there
can be sub sampling

660
00:25:40,375 --> 00:25:42,489
due to pool, straight
convolution and pooling.

661
00:25:42,489 --> 00:25:44,943
But in general, the, the
size of each activation map

662
00:25:44,943 --> 00:25:47,756
will be linear in the
size of the input image.

663
00:25:50,492 --> 00:25:52,762
So another, another kind
of useful thing we can do

664
00:25:52,762 --> 00:25:55,625
for visualizing
intermediate features is...

665
00:25:55,625 --> 00:25:58,850
Visualizing what types of
patches from input images

666
00:25:58,850 --> 00:26:01,293
cause maximal activation in different,

667
00:26:01,293 --> 00:26:03,453
different features, different neurons.

668
00:26:03,453 --> 00:26:06,052
So what we've done here
is that, we pick...

669
00:26:06,052 --> 00:26:08,605
Maybe again the con five
layer from Alex Net?

670
00:26:08,605 --> 00:26:10,926
And remember each of
these activation volumes

671
00:26:10,926 --> 00:26:12,936
at the con, at the con
five in Alex net gives us

672
00:26:12,936 --> 00:26:15,738
a 128 by 13 by 13 chunk of numbers.

673
00:26:15,738 --> 00:26:17,977
Then we'll pick one of those 128 channels.

674
00:26:17,977 --> 00:26:19,644
Maybe channel 17

675
00:26:19,644 --> 00:26:21,972
and now what we'll do is run many images

676
00:26:21,972 --> 00:26:23,749
through this convolutional network.

677
00:26:23,749 --> 00:26:25,689
And then, for each of those images

678
00:26:25,689 --> 00:26:27,456
record the con five features

679
00:26:27,456 --> 00:26:30,917
and then look at the...

680
00:26:30,917 --> 00:26:32,684
Right, so, then, then look at the, the...

681
00:26:32,684 --> 00:26:35,001
The parts of that 17th feature map

682
00:26:35,001 --> 00:26:37,925
that are maximally activated
over our data set of images.

683
00:26:37,925 --> 00:26:40,398
And now, because again this
is a convolutional layer

684
00:26:40,398 --> 00:26:42,875
each of those neurons in
the convolutional layer

685
00:26:42,875 --> 00:26:45,161
has some small receptive
field in the input.

686
00:26:45,161 --> 00:26:47,242
Each of those neurons is not
looking at the whole image.

687
00:26:47,242 --> 00:26:49,239
They're only looking at
the sub set of the image.

688
00:26:49,239 --> 00:26:51,758
Then what we'll do is,
is visualize the patches

689
00:26:51,758 --> 00:26:54,052
from the, from this
large data set of images

690
00:26:54,052 --> 00:26:56,479
corresponding to the maximal activations

691
00:26:56,479 --> 00:26:59,175
of that, of that feature,
of that particular feature

692
00:26:59,175 --> 00:27:00,731
in that particular layer.

693
00:27:00,731 --> 00:27:02,347
And then we can sorts these out,

694
00:27:02,347 --> 00:27:04,411
sort these patches by their activation

695
00:27:04,411 --> 00:27:06,177
at that, at that particular layer.

696
00:27:06,177 --> 00:27:09,448
So here is a, some examples from this...

697
00:27:09,448 --> 00:27:11,354
Network called a, fully...

698
00:27:11,354 --> 00:27:12,575
The network doesn't matter.

699
00:27:12,575 --> 00:27:14,053
But these are some visualizations

700
00:27:14,053 --> 00:27:16,380
of these kind of maximally
activating patches.

701
00:27:16,380 --> 00:27:18,487
So, each, each row gives...

702
00:27:18,487 --> 00:27:20,962
We've chosen one layer from or one neuron

703
00:27:20,962 --> 00:27:22,500
from one layer of a network

704
00:27:22,500 --> 00:27:25,216
and then each, and then,
the, they're sorted

705
00:27:25,216 --> 00:27:28,280
of these are the patches from
some large data set of images.

706
00:27:28,280 --> 00:27:30,611
That maximally activated this one neuron.

707
00:27:30,611 --> 00:27:33,277
And these can give you a sense
for what type of features

708
00:27:33,277 --> 00:27:35,698
these, these neurons might be looking for.

709
00:27:35,698 --> 00:27:37,049
So for example, this top row

710
00:27:37,049 --> 00:27:39,998
we see a lot of circly kinds
of things in the image.

711
00:27:39,998 --> 00:27:42,250
Some eyes, some, mostly eyes.

712
00:27:42,250 --> 00:27:44,621
But also this, kind of blue circly region.

713
00:27:44,621 --> 00:27:46,878
So then, maybe this,
this particular neuron

714
00:27:46,878 --> 00:27:48,878
in this particular layer of
this network is looking for

715
00:27:48,878 --> 00:27:51,303
kind of blue circly things in the input.

716
00:27:51,303 --> 00:27:52,986
Or maybe in the middle here

717
00:27:52,986 --> 00:27:54,596
we have neurons that are looking for

718
00:27:54,596 --> 00:27:56,200
text in different colors

719
00:27:56,200 --> 00:27:59,184
or, or maybe curving, curving edges

720
00:27:59,184 --> 00:28:02,201
of different colors and orientations.

721
00:28:06,246 --> 00:28:08,138
Yeah, so, I've been a little bit loose

722
00:28:08,138 --> 00:28:09,199
with terminology here.

723
00:28:09,199 --> 00:28:12,139
So, I'm saying that a
neuron is one scaler value

724
00:28:12,139 --> 00:28:13,970
in that con five activation map.

725
00:28:13,970 --> 00:28:15,582
But because it's convolutional,

726
00:28:15,582 --> 00:28:17,573
all the neurons in one channel

727
00:28:17,573 --> 00:28:19,283
are all using the same weights.

728
00:28:19,283 --> 00:28:22,197
So we've chosen one
channel and then, right?

729
00:28:22,197 --> 00:28:25,169
So, you get a lot of neurons
for each convolutional filter

730
00:28:25,169 --> 00:28:26,451
at any one layer.

731
00:28:26,451 --> 00:28:27,620
So, we, we could have been,

732
00:28:27,620 --> 00:28:29,317
so this patches could've
been drawn from anywhere

733
00:28:29,317 --> 00:28:32,532
in the image due to the
convolutional nature of the thing.

734
00:28:32,532 --> 00:28:34,036
And now at the bottom we also see

735
00:28:34,036 --> 00:28:35,533
some maximally activating patches

736
00:28:35,533 --> 00:28:38,721
for neurons from a higher up
layer in the same network.

737
00:28:38,721 --> 00:28:40,969
And now because they are coming
from higher in the network

738
00:28:40,969 --> 00:28:42,294
they have a larger receptive field.

739
00:28:42,294 --> 00:28:44,851
So, they're looking at larger
patches of the input image

740
00:28:44,851 --> 00:28:46,423
and we can also see
that they're looking for

741
00:28:46,423 --> 00:28:49,213
maybe larger structures
in the input image.

742
00:28:49,213 --> 00:28:51,709
So this, this second row is maybe looking,

743
00:28:51,709 --> 00:28:53,675
it seems to be looking for human,

744
00:28:53,675 --> 00:28:56,445
humans or maybe human faces.

745
00:28:56,445 --> 00:28:59,478
We have maybe something looking for...

746
00:28:59,478 --> 00:29:01,779
Parts of cameras or
different types of larger,

747
00:29:01,779 --> 00:29:06,410
larger, larger object like
type things, types of things.

748
00:29:06,410 --> 00:29:08,321
Another, another cool experiment we can do

749
00:29:08,321 --> 00:29:11,885
which comes from Zeiler
and Fergus ECCV 2014 paper.

750
00:29:11,885 --> 00:29:14,062
is this idea of an exclusion experiment.

751
00:29:14,062 --> 00:29:16,152
So, what we want to do is figure out

752
00:29:16,152 --> 00:29:18,634
which parts of the
input, of the input image

753
00:29:18,634 --> 00:29:21,659
cause the network to make
it's classification decision.

754
00:29:21,659 --> 00:29:23,976
So, what we'll do is,
we'll take our input image

755
00:29:23,976 --> 00:29:25,339
in this case an elephant

756
00:29:25,339 --> 00:29:27,321
and then we'll block
out some part of that,

757
00:29:27,321 --> 00:29:28,854
some region in that input image

758
00:29:28,854 --> 00:29:31,366
and just replace it with
the mean pixel value

759
00:29:31,366 --> 00:29:32,486
from the data set.

760
00:29:32,486 --> 00:29:34,926
And now, run that
occluded image throughout,

761
00:29:34,926 --> 00:29:36,754
through the network and then record

762
00:29:36,754 --> 00:29:39,583
what is the predicted probability
of this occluded image?

763
00:29:39,583 --> 00:29:42,297
And now slide this occluded
patch over every position

764
00:29:42,297 --> 00:29:44,752
in the input image and then
repeat the same process.

765
00:29:44,752 --> 00:29:46,800
And then draw this heat map showing,

766
00:29:46,800 --> 00:29:49,817
what was the predicted probability
output from the network

767
00:29:49,817 --> 00:29:51,339
as a function of where did,

768
00:29:51,339 --> 00:29:53,699
which part of the input
image did we occlude?

769
00:29:53,699 --> 00:29:55,072
And the idea is that

770
00:29:55,072 --> 00:29:57,129
if when we block out
some part of the image

771
00:29:57,129 --> 00:29:59,952
if that causes the network
score to change drastically.

772
00:29:59,952 --> 00:30:01,865
Then probably that part of the input image

773
00:30:01,865 --> 00:30:04,809
was really important for
the classification decision.

774
00:30:04,809 --> 00:30:06,428
So here we've shown...

775
00:30:06,428 --> 00:30:09,204
I've shown three different examples of...

776
00:30:09,204 --> 00:30:11,420
Of this occlusion type experiment.

777
00:30:11,420 --> 00:30:14,456
So, maybe this example of
a Go-kart at the bottom,

778
00:30:14,456 --> 00:30:16,188
you can see over here that

779
00:30:16,188 --> 00:30:17,997
when we, so here, red,

780
00:30:17,997 --> 00:30:20,225
the, the red corresponds
to a low probability

781
00:30:20,225 --> 00:30:23,077
and the white and yellow
corresponds to a high probability.

782
00:30:23,077 --> 00:30:24,993
So when we block out
the region of the image

783
00:30:24,993 --> 00:30:27,127
corresponding to this Go-kart in front.

784
00:30:27,127 --> 00:30:28,348
Then the predicted probability

785
00:30:28,348 --> 00:30:30,348
for the Go-kart class drops a lot.

786
00:30:30,348 --> 00:30:31,625
So that gives us some sense

787
00:30:31,625 --> 00:30:34,386
that the network is actually
caring a lot about these,

788
00:30:34,386 --> 00:30:36,047
these pixels in the input image

789
00:30:36,047 --> 00:30:38,419
in order to make it's
classification decision.

790
00:30:38,419 --> 00:30:39,589
Question?

791
00:30:47,473 --> 00:30:48,715
Yes, the question is that,

792
00:30:48,715 --> 00:30:49,780
what's going on in the background?

793
00:30:49,780 --> 00:30:51,830
So maybe if the image is a
little bit too small to tell

794
00:30:51,830 --> 00:30:53,444
but, there's, this is
actually a Go-kart track

795
00:30:53,444 --> 00:30:56,020
and there's a couple other
Go-karts in the background.

796
00:30:56,020 --> 00:30:57,664
So I think that, when
you're blocking out these

797
00:30:57,664 --> 00:30:58,785
other Go-karts in the background,

798
00:30:58,785 --> 00:31:00,395
that's also influencing the score

799
00:31:00,395 --> 00:31:02,003
or maybe like the horizon is there

800
00:31:02,003 --> 00:31:03,582
and maybe the horizon is an useful feature

801
00:31:03,582 --> 00:31:04,628
for detecting Go-karts,

802
00:31:04,628 --> 00:31:07,359
it's a little bit hard to tell sometimes.

803
00:31:07,359 --> 00:31:08,976
But this is a pretty cool visualization.

804
00:31:08,976 --> 00:31:10,118
Yeah, was there another question?

805
00:31:20,486 --> 00:31:22,106
So the question is, sorry,

806
00:31:22,106 --> 00:31:23,500
sorry, what was the first question?

807
00:31:30,731 --> 00:31:32,173
So, the, so the question...

808
00:31:32,173 --> 00:31:34,482
So for, for this example
we're taking one image

809
00:31:34,482 --> 00:31:36,802
and then masking all parts of one image.

810
00:31:36,802 --> 00:31:38,777
The second question
was, how is this useful?

811
00:31:38,777 --> 00:31:40,804
It's not, maybe, you don't
really take this information

812
00:31:40,804 --> 00:31:42,982
and then loop it directly
into the training process.

813
00:31:42,982 --> 00:31:45,036
Instead, this is a way, a tool for humans

814
00:31:45,036 --> 00:31:47,818
to understand, what types of computations

815
00:31:47,818 --> 00:31:49,341
these train networks are doing.

816
00:31:49,341 --> 00:31:50,759
So it's more for your understanding

817
00:31:50,759 --> 00:31:54,296
than for improving performance per se.

818
00:31:54,296 --> 00:31:56,030
So another, another related idea

819
00:31:56,030 --> 00:31:57,890
is this concept of a Saliency Map.

820
00:31:57,890 --> 00:32:00,534
Which is something that you
will see in your homeworks.

821
00:32:00,534 --> 00:32:02,578
So again, we have the same question

822
00:32:02,578 --> 00:32:05,366
of given an input image
of a dog in this case

823
00:32:05,366 --> 00:32:07,831
and the predicted class label of dog

824
00:32:07,831 --> 00:32:10,085
we want to know which
pixels in the input image

825
00:32:10,085 --> 00:32:11,796
are important for classification.

826
00:32:11,796 --> 00:32:14,761
We saw masking, is one way
to get at this question.

827
00:32:14,761 --> 00:32:17,525
But Saliency Maps are another, another,

828
00:32:17,525 --> 00:32:19,452
angle for attacking this problem.

829
00:32:19,452 --> 00:32:22,459
And the question is, and
one relatively simple idea

830
00:32:22,459 --> 00:32:25,354
from Karen Simonenian's
paper, a couple years ago.

831
00:32:25,354 --> 00:32:27,699
Is, this is just computing the gradient

832
00:32:27,699 --> 00:32:29,187
of the predicted class score

833
00:32:29,187 --> 00:32:31,694
with respect to the
pixels of the input image.

834
00:32:31,694 --> 00:32:33,025
And this will directly tell us

835
00:32:33,025 --> 00:32:36,042
in this sort of, first
order approximation sense.

836
00:32:36,042 --> 00:32:38,918
For each input, for each
pixel in the input image

837
00:32:38,918 --> 00:32:40,718
if we wiggle that pixel a little bit

838
00:32:40,718 --> 00:32:42,581
then how much will the
classification score

839
00:32:42,581 --> 00:32:43,963
for the class change?

840
00:32:43,963 --> 00:32:46,729
And this is another way
to get at this question

841
00:32:46,729 --> 00:32:50,496
of which pixels in the input
matter for the classification.

842
00:32:50,496 --> 00:32:52,246
And when we, and when we run

843
00:32:52,246 --> 00:32:54,888
for example Saliency,
where computer Saliency map

844
00:32:54,888 --> 00:32:57,115
for this dog, we see kind of a nice

845
00:32:57,115 --> 00:32:59,356
outline of a dog in the image.

846
00:32:59,356 --> 00:33:01,564
Which tells us that these
are probably the pixels

847
00:33:01,564 --> 00:33:04,985
of that, network is actually
looking at, for this image.

848
00:33:04,985 --> 00:33:06,618
And when we repeat this type of process

849
00:33:06,618 --> 00:33:08,551
for different images, we get some sense

850
00:33:08,551 --> 00:33:11,675
that the network is sort of
looking at the right regions.

851
00:33:11,675 --> 00:33:13,360
Which is somewhat comforting.

852
00:33:13,360 --> 00:33:14,462
Question?

853
00:33:17,407 --> 00:33:19,228
The question is, do
people use Saliency Maps

854
00:33:19,228 --> 00:33:21,916
for semantic segmentation?
The answer is yes.

855
00:33:21,916 --> 00:33:23,925
That actually was...

856
00:33:23,925 --> 00:33:26,741
Yeah, you guys are like really
on top of it this lecture.

857
00:33:26,741 --> 00:33:29,513
So that was another component,
again in Karen's paper.

858
00:33:29,513 --> 00:33:31,685
Where there's this idea
that maybe you can use these

859
00:33:31,685 --> 00:33:34,126
Saliency Maps to perform
semantic segmentation

860
00:33:34,126 --> 00:33:36,485
without direct, without any labeled data

861
00:33:36,485 --> 00:33:38,925
for the, for these, for these segments.

862
00:33:38,925 --> 00:33:41,718
So here they're using this
Grabcut Segmentation Algorithm

863
00:33:41,718 --> 00:33:43,908
which I don't really want
to get into the details of.

864
00:33:43,908 --> 00:33:46,015
But it's kind of an interactive
segmentation algorithm

865
00:33:46,015 --> 00:33:47,772
that you can use.

866
00:33:47,772 --> 00:33:49,699
So then when you combine this Saliency Map

867
00:33:49,699 --> 00:33:51,708
with this Grabcut Segmentation Algorithm

868
00:33:51,708 --> 00:33:54,288
then you can in fact,
sometimes segment out

869
00:33:54,288 --> 00:33:55,697
the object in the image.

870
00:33:55,697 --> 00:33:57,314
Which is really cool.

871
00:33:57,314 --> 00:33:58,745
However I'd like to point out

872
00:33:58,745 --> 00:34:00,326
that this is a little bit brittle

873
00:34:00,326 --> 00:34:02,528
and in general if you,
this will probably work

874
00:34:02,528 --> 00:34:04,378
much, much, much, worse than a network

875
00:34:04,378 --> 00:34:07,182
which did have access to
supervision and training time.

876
00:34:07,182 --> 00:34:10,534
So, I don't, I'm not sure
how, how practical this is.

877
00:34:10,534 --> 00:34:13,458
But it is pretty cool
that it works at all.

878
00:34:13,458 --> 00:34:15,598
But it probably works much
less than something trained

879
00:34:15,599 --> 00:34:19,025
explicitly to segment with supervision.

880
00:34:19,025 --> 00:34:21,200
So kind of another, another related idea

881
00:34:21,201 --> 00:34:23,791
is this idea of, of
guided back propagation.

882
00:34:23,791 --> 00:34:26,577
So again, we still want
to answer the question of

883
00:34:26,577 --> 00:34:30,001
for one particular, for
one particular image.

884
00:34:30,001 --> 00:34:32,522
Then now instead of
looking at the class score

885
00:34:32,522 --> 00:34:35,489
we want to know, we want to
pick some intermediate neuron

886
00:34:35,489 --> 00:34:37,420
in the network and ask again,

887
00:34:37,420 --> 00:34:39,143
which parts of the input image

888
00:34:39,143 --> 00:34:42,228
influence the score of that neuron,

889
00:34:42,228 --> 00:34:44,199
that internal neuron in the network.

890
00:34:44,199 --> 00:34:46,686
And, and then you could
imagine, again you could imagine

891
00:34:46,687 --> 00:34:49,059
computing a Saliency Map
for this again, right?

892
00:34:49,059 --> 00:34:51,772
That rather than computing the
gradient of the class scores

893
00:34:51,772 --> 00:34:53,466
with respect to the pixels of the image.

894
00:34:53,466 --> 00:34:56,356
You could compute the gradient
of some intermediate value

895
00:34:56,356 --> 00:34:58,815
in the network with respect
to the pixels of the image.

896
00:34:58,815 --> 00:35:00,582
And that would tell us again

897
00:35:00,582 --> 00:35:02,861
which parts, which
pixels in the input image

898
00:35:02,861 --> 00:35:05,832
influence that value of
that particular neuron.

899
00:35:05,832 --> 00:35:08,342
And that would be using
normal back propagation.

900
00:35:08,342 --> 00:35:10,332
But it turns out that
there is a slight tweak

901
00:35:10,332 --> 00:35:12,756
that we can do to this
back propagation procedure

902
00:35:12,756 --> 00:35:15,093
that ends up giving some
slightly cleaner images.

903
00:35:15,093 --> 00:35:17,786
So that's this idea of
guided back propagation

904
00:35:17,786 --> 00:35:21,393
that again comes from Zeiler
and Fergus's 2014 paper.

905
00:35:21,393 --> 00:35:24,203
And I don't really want to get
into the details too much here

906
00:35:24,203 --> 00:35:26,474
but, it, you just, it's
kind of weird tweak

907
00:35:26,474 --> 00:35:28,358
where you change the way
that you back propagate

908
00:35:28,358 --> 00:35:30,220
through relu non-linearities.

909
00:35:30,220 --> 00:35:32,772
And you sort of, only, only back propagate

910
00:35:32,772 --> 00:35:34,289
positive gradients through relu's

911
00:35:34,289 --> 00:35:35,452
and you do not back propagate

912
00:35:35,452 --> 00:35:37,254
negative gradients through the relu's.

913
00:35:37,254 --> 00:35:40,007
So you're no longer
computing the true gradient

914
00:35:40,007 --> 00:35:42,212
instead you're kind of only keeping track

915
00:35:42,212 --> 00:35:44,585
of positive influences

916
00:35:44,585 --> 00:35:46,948
on throughout the entire network.

917
00:35:46,948 --> 00:35:49,280
So maybe you should read
through these, these papers

918
00:35:49,280 --> 00:35:51,323
reference to your, if you
want a little bit more details

919
00:35:51,323 --> 00:35:53,614
about why that's a good idea.

920
00:35:53,614 --> 00:35:56,835
But empirically, when you
do guided back propagation

921
00:35:56,835 --> 00:35:59,133
as appose to regular back propagation.

922
00:35:59,133 --> 00:36:01,649
You tend to get much
cleaner, nicer images.

923
00:36:01,649 --> 00:36:04,864
that tells you, which part,
which pixel of the input image

924
00:36:04,864 --> 00:36:07,223
influence that particular neuron.

925
00:36:07,223 --> 00:36:09,488
So, again we were seeing
the same visualization

926
00:36:09,488 --> 00:36:12,467
we saw a few slides ago of the
maximally activating patches.

927
00:36:16,488 --> 00:36:18,170
But now, in addition to visualizing

928
00:36:18,170 --> 00:36:20,174
these maximally activating patches.

929
00:36:20,174 --> 00:36:22,576
We've also performed
guided back propagation,

930
00:36:22,576 --> 00:36:26,083
to tell us exactly which parts
of these patches influence

931
00:36:26,083 --> 00:36:27,604
the score of that neuron.

932
00:36:27,604 --> 00:36:29,527
So, remember for this example at the top,

933
00:36:29,527 --> 00:36:31,598
we saw that, we thought this neuron

934
00:36:31,598 --> 00:36:33,751
is may be looking for circly tight things,

935
00:36:33,751 --> 00:36:34,726
in the input patch

936
00:36:34,726 --> 00:36:37,139
because there're allot
of circly tight patches.

937
00:36:37,139 --> 00:36:39,294
Well, when we look at
guided back propagation

938
00:36:39,294 --> 00:36:42,028
We can see with that intuition
is somewhat confirmed

939
00:36:42,028 --> 00:36:45,819
because it is indeed the circly
parts of that input patch

940
00:36:45,819 --> 00:36:49,218
which are influencing
that, that neuron value.

941
00:36:49,218 --> 00:36:52,251
So, this is kind of a useful
to all for synthesizing.

942
00:36:52,251 --> 00:36:54,064
For understanding what these
different intermediates

943
00:36:54,064 --> 00:36:56,514
are looking for.

944
00:36:56,514 --> 00:36:58,917
But, one kind of interesting thing

945
00:36:58,917 --> 00:37:00,398
about guided back propagation

946
00:37:00,398 --> 00:37:01,968
or computing saliency maps.

947
00:37:01,968 --> 00:37:05,108
Is that there's always a
function of fixed input image,

948
00:37:05,108 --> 00:37:08,131
right, they're telling us
for a fixed input image,

949
00:37:08,131 --> 00:37:11,532
which pixel or which parts
of that input image influence

950
00:37:11,532 --> 00:37:12,882
the value of the neuron.

951
00:37:12,882 --> 00:37:15,961
Another question you might answer is

952
00:37:15,961 --> 00:37:19,110
is remove this reliance, on
that, on some input image.

953
00:37:19,110 --> 00:37:22,446
And then instead just ask
what type of input in general

954
00:37:22,446 --> 00:37:24,641
would cause this neuron to activate

955
00:37:24,641 --> 00:37:26,003
and we can answer this question

956
00:37:26,003 --> 00:37:29,118
using a technical Gradient ascent

957
00:37:29,118 --> 00:37:31,424
so, remember we always use Gradient decent

958
00:37:31,424 --> 00:37:34,903
to train our convolutional
networks by minimizing the loss.

959
00:37:34,903 --> 00:37:37,815
Instead now, we want to fix the, fix

960
00:37:37,815 --> 00:37:40,552
the weight of our trained
convolutional network

961
00:37:40,552 --> 00:37:44,225
and instead synthesizing image
by performing Gradient ascent

962
00:37:44,225 --> 00:37:46,806
on the pixels of the
image to try and maximize

963
00:37:46,806 --> 00:37:50,932
the score of some intermediate
neuron or of some class.

964
00:37:50,932 --> 00:37:54,171
So, in a process of Gradient ascent,

965
00:37:54,171 --> 00:37:57,019
we're no longer optimizing
over the weights of the network

966
00:37:57,019 --> 00:37:58,333
those weights remained fixed

967
00:37:58,333 --> 00:38:01,385
instead we're trying to change
pixels of some input image

968
00:38:01,385 --> 00:38:03,658
to cause this neuron,
or this neuron value,

969
00:38:03,658 --> 00:38:07,104
or this class score to
maximally, to be maximized

970
00:38:07,104 --> 00:38:08,532
but, instead but, in addition

971
00:38:08,532 --> 00:38:10,475
we need some regularization term

972
00:38:10,475 --> 00:38:12,136
so, remember we always a,

973
00:38:12,136 --> 00:38:14,857
we before seeing regularization terms

974
00:38:14,857 --> 00:38:16,987
to try to prevent the network weights

975
00:38:16,987 --> 00:38:19,078
from over fitting to the training data.

976
00:38:19,078 --> 00:38:20,830
Now, we need something kind of similar

977
00:38:20,830 --> 00:38:23,311
to prevent the pixels
of our generated image

978
00:38:23,311 --> 00:38:25,470
from over fitting to the peculiarities

979
00:38:25,470 --> 00:38:27,109
of that particular network.

980
00:38:27,109 --> 00:38:30,235
So, here we'll often incorporate
some regularization term

981
00:38:30,235 --> 00:38:33,260
that, we're kind of, we
want a generated image

982
00:38:33,260 --> 00:38:34,664
of two properties

983
00:38:34,664 --> 00:38:37,396
one, we wanted to maximally activate some,

984
00:38:37,396 --> 00:38:39,269
some score or some neuron value.

985
00:38:39,269 --> 00:38:42,111
But, we also wanted to
look like a natural image.

986
00:38:42,111 --> 00:38:43,123
we wanted to kind of have,

987
00:38:43,123 --> 00:38:44,202
the kind of statistics

988
00:38:44,202 --> 00:38:46,485
that we typically see in natural images.

989
00:38:46,485 --> 00:38:49,013
So, these regularization
term in the subjective

990
00:38:49,013 --> 00:38:51,386
is something to enforce a generated image

991
00:38:51,386 --> 00:38:52,936
to look relatively natural.

992
00:38:52,936 --> 00:38:54,261
And we'll see a couple
of different examples

993
00:38:54,261 --> 00:38:57,116
of regualizers as we go through.

994
00:38:57,116 --> 00:38:58,719
But, the general strategy for this

995
00:38:58,719 --> 00:38:59,975
is actually pretty simple

996
00:38:59,975 --> 00:39:02,732
and again informant allot
of things of this nature

997
00:39:02,732 --> 00:39:04,371
on your assignment three.

998
00:39:04,371 --> 00:39:06,788
But, what we'll do is start
with some initial image

999
00:39:06,788 --> 00:39:10,410
either initializing to zeros
or to uniform or noise.

1000
00:39:10,410 --> 00:39:12,654
But, initialize your image in some way

1001
00:39:12,654 --> 00:39:14,944
and I'll repeat where
you forward your image

1002
00:39:14,944 --> 00:39:17,249
through 3D network and compute the score

1003
00:39:17,249 --> 00:39:19,922
or, or neuron value
that you're interested.

1004
00:39:19,922 --> 00:39:22,124
Now, back propagate to
compute the Gradient

1005
00:39:22,124 --> 00:39:26,643
of that neuron score with respect
to the pixels of the image

1006
00:39:26,643 --> 00:39:28,531
and then make a small Gradient ascent

1007
00:39:28,531 --> 00:39:30,046
or Gradient ascent update

1008
00:39:30,046 --> 00:39:32,071
to the pixels of the images itself.

1009
00:39:32,071 --> 00:39:33,897
To try and maximize that score.

1010
00:39:33,897 --> 00:39:35,625
And I'll repeat this
process over and over again,

1011
00:39:35,625 --> 00:39:38,786
until you have a beautiful image.

1012
00:39:38,786 --> 00:39:42,311
And, then we talked, we talked
about the image regularizer,

1013
00:39:42,311 --> 00:39:45,948
well a very simple, a very
simple idea for image regularizer

1014
00:39:45,948 --> 00:39:49,428
is simply to penalize L2
norm of a generated image

1015
00:39:49,428 --> 00:39:51,466
This is not so semantically meaningful,

1016
00:39:51,466 --> 00:39:54,918
it's just does something,
and this was one of the,

1017
00:39:54,918 --> 00:39:56,899
one of the earliest
regularizer that we've seen

1018
00:39:56,899 --> 00:40:00,604
in the literature for these
type of generating images type

1019
00:40:00,604 --> 00:40:01,764
of papers.

1020
00:40:01,764 --> 00:40:04,787
And, when you run this
on a trained network

1021
00:40:04,787 --> 00:40:07,759
you can see that now we're
trying to generate images

1022
00:40:07,759 --> 00:40:10,287
that maximize the dumble score

1023
00:40:10,287 --> 00:40:12,153
in the upper left hand
corner here for example.

1024
00:40:12,153 --> 00:40:14,820
And, then you can see that
the synthesized image,

1025
00:40:14,820 --> 00:40:17,006
it been, it's little
bit hard to see may be

1026
00:40:17,006 --> 00:40:19,726
but there're allot of
different dumble like shapes,

1027
00:40:19,726 --> 00:40:21,016
all kind of super impose

1028
00:40:21,016 --> 00:40:23,162
that different portions of the image.

1029
00:40:23,162 --> 00:40:25,371
or if we try to generate an image for cups

1030
00:40:25,371 --> 00:40:27,685
then we can may be see a
bunch of different cups

1031
00:40:27,685 --> 00:40:29,111
all kind of super imposed

1032
00:40:29,111 --> 00:40:30,466
the Dalmatian is pretty cool,

1033
00:40:30,466 --> 00:40:32,129
because now we can see kind of this black

1034
00:40:32,129 --> 00:40:33,303
and white spotted pattern

1035
00:40:33,303 --> 00:40:35,478
that's kind of
characteristics of Dalmatians

1036
00:40:35,478 --> 00:40:37,538
or for lemons we can see
these different kinds

1037
00:40:37,538 --> 00:40:40,388
of yellow splotches in the image.

1038
00:40:40,388 --> 00:40:41,946
And there's a couple
of more examples here,

1039
00:40:41,946 --> 00:40:43,539
I think may be the goose is kind of cool

1040
00:40:43,539 --> 00:40:46,514
or the kitfox are actually
may be looks like kitfox.

1041
00:40:46,514 --> 00:40:47,454
Question?

1042
00:40:55,528 --> 00:40:57,929
The question is, why are
these all rainbow colored

1043
00:40:57,929 --> 00:41:00,501
and in general getting true colors out

1044
00:41:00,501 --> 00:41:02,434
of this visualization is pretty tricky.

1045
00:41:02,434 --> 00:41:04,567
Right, because any, any actual image will

1046
00:41:04,567 --> 00:41:06,693
be bounded in the range zero to 255.

1047
00:41:06,693 --> 00:41:08,237
So, it really should be some kind

1048
00:41:08,237 --> 00:41:10,395
of constrained optimization problem

1049
00:41:10,395 --> 00:41:13,238
But, if, for using this generic
methods for Gradient ascent

1050
00:41:13,238 --> 00:41:15,721
then we, that's going to
be unconstrained problem.

1051
00:41:15,721 --> 00:41:19,863
So, you may be use like projector
Gradient ascent algorithm

1052
00:41:19,863 --> 00:41:21,848
or your rescaled image at the end.

1053
00:41:21,848 --> 00:41:24,389
So, the colors that you
see in this visualizations,

1054
00:41:24,389 --> 00:41:27,799
sometimes are you cannot
take them too seriously.

1055
00:41:27,799 --> 00:41:28,702
Question?

1056
00:41:32,801 --> 00:41:34,179
The question is what happens, if you let

1057
00:41:34,179 --> 00:41:36,846
the thing loose and don't
put any regularizer on it.

1058
00:41:36,846 --> 00:41:40,792
Well, then you tend to get
an image which maximize

1059
00:41:40,792 --> 00:41:42,884
the score which is confidently classified

1060
00:41:42,884 --> 00:41:44,860
as the class you wanted

1061
00:41:44,860 --> 00:41:46,648
but, usually it doesn't
look like anything.

1062
00:41:46,648 --> 00:41:48,522
It kind of look likes random noise.

1063
00:41:48,522 --> 00:41:51,035
So, that's kind of an
interesting property in itself

1064
00:41:51,035 --> 00:41:54,538
that will go into much more
detail in a future lecture.

1065
00:41:54,538 --> 00:41:57,483
But, that's why, that
kind of doesn't help you

1066
00:41:57,483 --> 00:41:59,662
so much for understanding what things

1067
00:41:59,662 --> 00:42:00,913
the network is looking for.

1068
00:42:00,913 --> 00:42:02,662
So, if we want to understand,

1069
00:42:02,662 --> 00:42:04,386
why the network thing makes its decisions

1070
00:42:04,386 --> 00:42:06,193
then it's kind of useful
to put regularizer

1071
00:42:06,193 --> 00:42:09,607
on there to generate an
image to look more natural.

1072
00:42:09,607 --> 00:42:10,471
A question in the back.

1073
00:42:34,416 --> 00:42:35,668
Yeah, so the question
is that we see a lot of

1074
00:42:35,668 --> 00:42:38,492
multi modality here, and
other ways to combat that.

1075
00:42:38,492 --> 00:42:40,124
And actually yes, we'll see that,

1076
00:42:40,124 --> 00:42:41,754
this is kind of first
step in the whole line

1077
00:42:41,754 --> 00:42:44,847
of work in improving these visualizations.

1078
00:42:44,847 --> 00:42:47,867
So, another, another kind
of, so then the angle here

1079
00:42:47,867 --> 00:42:49,338
is a kind of to improve the regularizer

1080
00:42:49,338 --> 00:42:51,517
to improve our visualized images.

1081
00:42:51,517 --> 00:42:54,466
And there's a another
paper from Jason Yesenski

1082
00:42:54,466 --> 00:42:55,760
and some of his collaborators where

1083
00:42:55,760 --> 00:42:58,621
they added some additional
impressive regularizers.

1084
00:42:58,621 --> 00:43:00,924
So, in addition to this
L2 norm constraint,

1085
00:43:00,924 --> 00:43:04,108
in addition we also periodically
during optimization,

1086
00:43:04,108 --> 00:43:06,213
and do some gauche and
blurring on the image,

1087
00:43:06,213 --> 00:43:07,534
we're also clip some,.

1088
00:43:07,534 --> 00:43:09,659
some small value, some small pixel values

1089
00:43:09,659 --> 00:43:12,441
all the way to zero, we're
also clip some of the,

1090
00:43:12,441 --> 00:43:14,694
some of the pixel values
of low Gradients to zero

1091
00:43:14,694 --> 00:43:15,840
So, you can see this is kind of

1092
00:43:15,840 --> 00:43:17,559
a projector Gradient ascent algorithm

1093
00:43:17,559 --> 00:43:20,022
where it reach periodically
we're projecting

1094
00:43:20,022 --> 00:43:22,615
our generated image onto some nicer set

1095
00:43:22,615 --> 00:43:24,555
of images with some nicer properties.

1096
00:43:24,555 --> 00:43:26,179
For example, special smoothness

1097
00:43:26,179 --> 00:43:28,241
with respect to the gauchian blurring

1098
00:43:28,241 --> 00:43:30,597
So, when you do this, you
tend to get much nicer images

1099
00:43:30,597 --> 00:43:32,870
that are much clear to see.

1100
00:43:32,870 --> 00:43:35,175
So, now these flamingos
look like flamingos

1101
00:43:35,175 --> 00:43:38,553
the ground beetle is starting
to look more beetle like

1102
00:43:38,553 --> 00:43:41,695
or this black swan maybe
looks like a black swan.

1103
00:43:41,695 --> 00:43:45,090
These billiard tables actually
look kind of impressive now,

1104
00:43:45,090 --> 00:43:48,211
where you can definitely see
this billiard table structure.

1105
00:43:48,211 --> 00:43:51,698
So, you can see that once you
add in nicer regularizers,

1106
00:43:51,698 --> 00:43:53,746
then the generated images become a bit,

1107
00:43:53,746 --> 00:43:55,209
a little bit cleaner.

1108
00:43:55,209 --> 00:43:56,831
And, now we can perform this procedure

1109
00:43:56,831 --> 00:43:58,728
not only for the final class course,

1110
00:43:58,728 --> 00:44:01,038
but also for these
intermediate neurons as well.

1111
00:44:01,038 --> 00:44:04,475
So, instead of trying to
maximize our billiard table score

1112
00:44:04,475 --> 00:44:06,698
for example instead we
can get maximize one

1113
00:44:06,698 --> 00:44:10,111
of the neurons from
some intermediate layer

1114
00:44:10,111 --> 00:44:11,118
Question.

1115
00:44:16,743 --> 00:44:19,393
So, the question is what's
with the for example here,

1116
00:44:19,393 --> 00:44:21,794
so those who remember
initializing our image randomly

1117
00:44:21,794 --> 00:44:22,880
so, these four images would

1118
00:44:22,880 --> 00:44:25,681
be different random
initialization of the input image.

1119
00:44:28,106 --> 00:44:30,426
And again, we can use these
same type of procedure

1120
00:44:30,426 --> 00:44:32,557
to visualize, to synthesis images

1121
00:44:32,557 --> 00:44:34,884
which maximally activate
intermediate neurons

1122
00:44:34,884 --> 00:44:36,113
of the network.

1123
00:44:36,113 --> 00:44:37,667
And, then you can get a sense from some

1124
00:44:37,667 --> 00:44:40,174
of these intermediate
neurons are looking for,

1125
00:44:40,174 --> 00:44:42,164
so may be at layer four there's neuron

1126
00:44:42,164 --> 00:44:44,605
that's kind of looking for spirally things

1127
00:44:44,605 --> 00:44:46,022
or there's neuron that's may be looking

1128
00:44:46,022 --> 00:44:47,646
for like chunks of caterpillars

1129
00:44:47,646 --> 00:44:49,703
it's a little bit harder to tell.

1130
00:44:49,703 --> 00:44:52,304
But, in generally as you
go larger up in the image

1131
00:44:52,304 --> 00:44:54,818
then you can see that
the one, the obviously

1132
00:44:54,818 --> 00:44:56,585
receptive fields of
these neurons are larger.

1133
00:44:56,585 --> 00:44:58,664
So, you're looking at the
larger patches in the image.

1134
00:44:58,664 --> 00:45:01,258
And they tend to be looking
for may be larger structures

1135
00:45:01,258 --> 00:45:03,549
or more complex patterns
in the input image.

1136
00:45:03,549 --> 00:45:04,802
That's pretty cool.

1137
00:45:07,499 --> 00:45:10,119
And, then people have
really gone crazy with this

1138
00:45:10,119 --> 00:45:13,611
and trying to, they basically
improve these visualization

1139
00:45:13,611 --> 00:45:15,559
by keeping on extra features

1140
00:45:15,559 --> 00:45:17,002
So, this was a cool paper kind

1141
00:45:17,002 --> 00:45:20,047
of explicitly trying to address this

1142
00:45:20,047 --> 00:45:22,417
multi modality, there's
someone asked question

1143
00:45:22,417 --> 00:45:23,697
about a few minutes ago.

1144
00:45:23,697 --> 00:45:26,088
So, here they were
trying to explicitly take

1145
00:45:26,088 --> 00:45:28,260
a count, take this multi
modality into account

1146
00:45:28,260 --> 00:45:29,849
in the optimization procedure

1147
00:45:29,849 --> 00:45:32,310
where they did indeed,
I think see the initial,

1148
00:45:32,310 --> 00:45:33,911
so they for each of the classes,

1149
00:45:33,911 --> 00:45:35,254
you run a clustering algorithm

1150
00:45:35,254 --> 00:45:38,260
to try to separate the
classes into different modes

1151
00:45:38,260 --> 00:45:40,378
and then initialize with something

1152
00:45:40,378 --> 00:45:42,667
that is close to one of those modes.

1153
00:45:42,667 --> 00:45:43,617
And, then when you do that,

1154
00:45:43,617 --> 00:45:45,890
you kind of account for
this multi modality.

1155
00:45:45,890 --> 00:45:50,309
so for intuition, on the
right here these eight images

1156
00:45:50,309 --> 00:45:51,675
are all of grocery stores.

1157
00:45:51,675 --> 00:45:53,713
But, the top row, is
kind of close up pictures

1158
00:45:53,713 --> 00:45:56,401
of produce on the shelf

1159
00:45:56,401 --> 00:45:59,068
and those are labeled as grocery stores

1160
00:45:59,068 --> 00:46:00,396
And the bottom row kind of shows

1161
00:46:00,396 --> 00:46:02,286
people walking around grocery stores

1162
00:46:02,286 --> 00:46:04,221
or at the checkout line
or something like that.

1163
00:46:04,221 --> 00:46:06,085
And, those are also labeled
those as grocery store,

1164
00:46:06,085 --> 00:46:08,073
but their visual appearance
is quiet different.

1165
00:46:08,073 --> 00:46:09,911
So, a lot of these classes
and that being sort

1166
00:46:09,911 --> 00:46:10,988
multi modal

1167
00:46:10,988 --> 00:46:12,767
And, if you can take, and
if you explicitly take

1168
00:46:12,767 --> 00:46:14,265
this more time mortality into account

1169
00:46:14,265 --> 00:46:17,648
when generating images, then
you can get nicer results.

1170
00:46:17,648 --> 00:46:19,263
And now, then when you look at some

1171
00:46:19,263 --> 00:46:22,569
of their example, synthesis
images for classes,

1172
00:46:22,569 --> 00:46:25,062
you can see like the
bell pepper, the card on,

1173
00:46:25,062 --> 00:46:28,224
strawberries, jackolantern now they end up

1174
00:46:28,224 --> 00:46:31,840
with some very beautifully
generated images.

1175
00:46:31,840 --> 00:46:33,324
And now, I don't want to get to much

1176
00:46:33,324 --> 00:46:35,416
into detail of the next slide.

1177
00:46:35,416 --> 00:46:38,177
But, then you can even go crazier.

1178
00:46:38,177 --> 00:46:40,700
and add an even stronger image prior

1179
00:46:40,700 --> 00:46:43,623
and generate some very
beautiful images indeed

1180
00:46:43,623 --> 00:46:45,727
So, these are all synthesized
images that are trying

1181
00:46:45,727 --> 00:46:48,921
to maximize the class score
or some image in a class.

1182
00:46:48,921 --> 00:46:50,969
But, the general idea is that rather

1183
00:46:50,969 --> 00:46:52,969
than optimizing directly the pixels

1184
00:46:52,969 --> 00:46:54,960
of the input image, instead they're trying

1185
00:46:54,960 --> 00:46:59,020
to optimize the FC6 representation
of that image instead.

1186
00:46:59,020 --> 00:47:01,392
And now they need to use some
feature inversion network

1187
00:47:01,392 --> 00:47:03,342
and I don't want to get
into the details here.

1188
00:47:03,342 --> 00:47:05,290
You should read the paper,
it's actually really cool

1189
00:47:05,290 --> 00:47:06,481
But, the point is that,

1190
00:47:06,481 --> 00:47:10,085
when you start adding additional priors

1191
00:47:10,085 --> 00:47:11,905
towards modeling natural images

1192
00:47:11,905 --> 00:47:14,388
and you can end generating
some quiet realistic images

1193
00:47:14,388 --> 00:47:16,662
they gave you some sense of
what the network is looking for

1194
00:47:18,951 --> 00:47:21,353
So, that's, that's sort of one cool thing

1195
00:47:21,353 --> 00:47:23,839
that we can do with this
strategy, but this idea

1196
00:47:23,839 --> 00:47:27,185
of trying to synthesis
images by using Gradients

1197
00:47:27,185 --> 00:47:29,893
on image pixels, is
actually super powerful.

1198
00:47:29,893 --> 00:47:32,175
And, another really cool
thing we can do with this,

1199
00:47:32,175 --> 00:47:34,288
is this concept of fooling image

1200
00:47:34,288 --> 00:47:37,523
So, what we can do is
pick some arbitrary image,

1201
00:47:37,523 --> 00:47:41,109
and then try to maximize the,
so, say we take it picture

1202
00:47:41,109 --> 00:47:43,362
of an elephant and then
we tell the network

1203
00:47:43,362 --> 00:47:44,929
that we want to, change the image

1204
00:47:44,929 --> 00:47:49,418
to maximize the score
of Koala bear instead

1205
00:47:49,418 --> 00:47:51,463
So, then what we were
doing is trying to change

1206
00:47:51,463 --> 00:47:54,724
that image of an elephant
to try and instead cause

1207
00:47:54,724 --> 00:47:57,064
the network to classify as a Koala bear.

1208
00:47:57,064 --> 00:47:59,033
And, what you might hope for is that,

1209
00:47:59,033 --> 00:48:01,966
maybe that elephant was
sort of thought more thing

1210
00:48:01,966 --> 00:48:05,210
into a Koala bear and
maybe he would sprout

1211
00:48:05,210 --> 00:48:05,931
little cute ears or something like that.

1212
00:48:05,931 --> 00:48:07,513
But, that's not what happens in practice,

1213
00:48:07,513 --> 00:48:09,241
which is pretty surprising.

1214
00:48:09,241 --> 00:48:11,548
Instead if you take this
picture of a elephant

1215
00:48:11,548 --> 00:48:12,833
and tell them that, tell them that

1216
00:48:12,833 --> 00:48:15,344
and try to change the
elephant image to instead

1217
00:48:15,344 --> 00:48:17,377
cause it to be classified as a koala bear

1218
00:48:17,377 --> 00:48:20,083
What you'll find is that, you is that

1219
00:48:20,083 --> 00:48:22,032
this second image on the right actually

1220
00:48:22,032 --> 00:48:23,270
is classified as koala bear

1221
00:48:23,270 --> 00:48:24,853
but it looks the same to us.

1222
00:48:24,853 --> 00:48:28,016
So that's pretty fishy
and pretty surprising.

1223
00:48:28,016 --> 00:48:32,120
So also on the bottom we've
taken this picture of a boat.

1224
00:48:32,120 --> 00:48:34,114
Schooner is the image in that class

1225
00:48:34,114 --> 00:48:37,170
and then we told the network
to classified as an iPod.

1226
00:48:37,170 --> 00:48:39,115
So now the second example looks just,

1227
00:48:39,115 --> 00:48:40,251
still looks like a boat to us

1228
00:48:40,251 --> 00:48:41,881
but the network thinks it's an iPod

1229
00:48:41,881 --> 00:48:45,032
and the difference is in
pixels between these two images

1230
00:48:45,032 --> 00:48:46,260
are basically nothing.

1231
00:48:46,260 --> 00:48:48,141
And if you magnify those differences

1232
00:48:48,141 --> 00:48:50,933
you don't really see any
iPod or Koala like features

1233
00:48:50,933 --> 00:48:52,025
on these differences,

1234
00:48:52,025 --> 00:48:54,630
they're just kind of like
random patterns of noise.

1235
00:48:54,630 --> 00:48:56,569
So the question is what's going here?

1236
00:48:56,569 --> 00:48:58,924
And like how can this possibly the case?

1237
00:48:58,924 --> 00:49:01,285
Well, we'll have a guest
lecture from Ian Goodfellow

1238
00:49:01,285 --> 00:49:03,635
in a week an half two weeks.

1239
00:49:03,635 --> 00:49:05,150
And he's going to go in much more detail

1240
00:49:05,150 --> 00:49:06,573
about this type of phenomenon

1241
00:49:06,573 --> 00:49:08,068
and that will be really exciting.

1242
00:49:08,068 --> 00:49:09,309
But I did want to mention it here

1243
00:49:09,309 --> 00:49:11,006
because it is on your homework.

1244
00:49:11,006 --> 00:49:11,595
Question?

1245
00:49:16,320 --> 00:49:17,513
Yeah, so that's something,

1246
00:49:17,513 --> 00:49:20,050
so the question is can we use
fooled images as training data

1247
00:49:20,050 --> 00:49:21,723
and I think, Ian's going
to go in much more detail

1248
00:49:21,723 --> 00:49:22,963
on all of these types of strategies.

1249
00:49:22,963 --> 00:49:23,780
Because that's literally,

1250
00:49:23,780 --> 00:49:27,214
that's really a whole lecture onto itself.

1251
00:49:27,214 --> 00:49:28,885
Question?

1252
00:50:00,608 --> 00:50:03,478
The question is why do we
care about any of this stuff?

1253
00:50:03,478 --> 00:50:06,693
Basically...

1254
00:50:06,693 --> 00:50:08,685
Okay, maybe that was a
mischaracterization, I am sorry.

1255
00:50:24,573 --> 00:50:27,028
Yeah, the question is
what is have in the...

1256
00:50:27,028 --> 00:50:28,744
understanding this intermediate neurons

1257
00:50:28,744 --> 00:50:29,797
how does that help our understanding

1258
00:50:29,797 --> 00:50:32,027
of the final classification.

1259
00:50:32,027 --> 00:50:34,313
So this is actually, this
whole field of trying

1260
00:50:34,313 --> 00:50:36,749
to visualize intermediates
is kind of in response

1261
00:50:36,749 --> 00:50:38,921
to a common criticism of deep learning.

1262
00:50:38,921 --> 00:50:41,496
So a common criticism of
deep learning is like,

1263
00:50:41,496 --> 00:50:43,011
you've got this big black box network

1264
00:50:43,011 --> 00:50:45,081
you trained it on gradient
ascent, you get a good number

1265
00:50:45,081 --> 00:50:47,350
and that's great but we
don't trust the network

1266
00:50:47,350 --> 00:50:49,081
because we don't understand as people

1267
00:50:49,081 --> 00:50:51,272
why it's making the
decisions, that's it's making.

1268
00:50:51,272 --> 00:50:53,628
So a lot of these type of
visualization techniques

1269
00:50:53,628 --> 00:50:55,650
were developed to try and address that

1270
00:50:55,650 --> 00:50:57,547
and try to understand as people

1271
00:50:57,547 --> 00:50:59,672
why the network are making
their various classification,

1272
00:50:59,672 --> 00:51:01,530
classification decisions a bit more.

1273
00:51:01,530 --> 00:51:03,419
Because if you contrast,

1274
00:51:03,419 --> 00:51:05,522
if you contrast a deep
convolutional neural network

1275
00:51:05,522 --> 00:51:07,722
with other machine running techniques.

1276
00:51:07,722 --> 00:51:10,493
Like linear models are much
easier to interpret in general

1277
00:51:10,493 --> 00:51:12,148
because you can look at
the weights and kind of

1278
00:51:12,148 --> 00:51:15,120
understand the interpretation
between how much each input

1279
00:51:15,120 --> 00:51:17,458
feature effect the decision or
if you look at something like

1280
00:51:17,458 --> 00:51:19,459
a random forest or decision tree.

1281
00:51:19,459 --> 00:51:20,750
Some other machine learning models

1282
00:51:20,750 --> 00:51:22,525
end up being a bit more interpretable

1283
00:51:22,525 --> 00:51:25,607
just by their very nature
then this sort of black box

1284
00:51:25,607 --> 00:51:27,442
convolutional networks.

1285
00:51:27,442 --> 00:51:30,202
So a lot of this is sort of
in response to that criticism

1286
00:51:30,202 --> 00:51:33,520
to say that, yes they are
these large complex models

1287
00:51:33,520 --> 00:51:36,138
but they are still doing some
interesting and interpretable

1288
00:51:36,138 --> 00:51:37,263
things under the hood.

1289
00:51:37,263 --> 00:51:38,895
They are not just totally going out

1290
00:51:38,895 --> 00:51:40,480
in randomly classifying things.

1291
00:51:40,480 --> 00:51:42,201
They are doing something meaningful

1292
00:51:44,891 --> 00:51:47,129
So another cool thing we can do with this

1293
00:51:47,129 --> 00:51:49,162
gradient based optimization of images

1294
00:51:49,162 --> 00:51:50,989
is this idea of DeepDream.

1295
00:51:50,989 --> 00:51:52,651
So this was a really cool blog post

1296
00:51:52,651 --> 00:51:55,592
that came out from
Google a year or two ago.

1297
00:51:55,592 --> 00:51:57,141
And the idea is that,

1298
00:51:57,141 --> 00:51:59,516
this is, so we talked
about scientific value,

1299
00:51:59,516 --> 00:52:00,859
this is almost entirely for fun.

1300
00:52:00,859 --> 00:52:02,520
So the point of this exercise is mostly

1301
00:52:02,520 --> 00:52:04,284
to generate cool images.

1302
00:52:04,284 --> 00:52:07,295
And aside, you also get
some sense for what features

1303
00:52:07,295 --> 00:52:08,807
images are looking at.

1304
00:52:08,807 --> 00:52:10,186
Or these networks are looking at.

1305
00:52:10,186 --> 00:52:12,219
So we can do is, we take our input image

1306
00:52:12,219 --> 00:52:15,275
we run it through the convolutional
network up to some layer

1307
00:52:15,275 --> 00:52:17,035
and now we back propagate

1308
00:52:17,035 --> 00:52:19,029
and set the gradient
of that, at that layer

1309
00:52:19,029 --> 00:52:20,742
equal to the activation value.

1310
00:52:20,742 --> 00:52:22,649
And now back propagate, back to the image

1311
00:52:22,649 --> 00:52:25,427
and update the image and
repeat, repeat, repeat.

1312
00:52:25,427 --> 00:52:28,108
So this has the interpretation
of trying to amplify

1313
00:52:28,108 --> 00:52:30,419
existing features that were
detected by the network

1314
00:52:30,419 --> 00:52:31,682
in this image. Right?

1315
00:52:31,682 --> 00:52:34,014
Because whatever features
existed on that layer

1316
00:52:34,014 --> 00:52:35,875
now we set the gradient
equal to the feature

1317
00:52:35,875 --> 00:52:37,382
and we just tell the network to amplify

1318
00:52:37,382 --> 00:52:40,010
whatever features you
already saw in that image.

1319
00:52:40,010 --> 00:52:42,415
And by the way you can also
see this as trying to maximize

1320
00:52:42,415 --> 00:52:46,918
the L2 norm of the features
at that layer of the image.

1321
00:52:46,918 --> 00:52:48,599
And it turns... And when you do this

1322
00:52:48,599 --> 00:52:50,480
the code ends up looking really simple.

1323
00:52:50,480 --> 00:52:52,628
So your code for many of
your homework assignments

1324
00:52:52,628 --> 00:52:54,357
will probably be about this complex

1325
00:52:54,357 --> 00:52:55,999
or maybe even a little bit a less so.

1326
00:52:55,999 --> 00:52:57,516
So the idea is that...

1327
00:52:57,516 --> 00:52:58,786
But there's a couple of tricks here

1328
00:52:58,786 --> 00:53:00,785
that you'll also see in your assignments.

1329
00:53:00,785 --> 00:53:02,595
So one trick is to jitter the image

1330
00:53:02,595 --> 00:53:04,443
before you compute your gradients.

1331
00:53:04,443 --> 00:53:06,844
So rather than running the
exact image through the network

1332
00:53:06,844 --> 00:53:09,160
instead you'll shift the
image over by two pixels

1333
00:53:09,160 --> 00:53:11,187
and kind of wrap the other
two pixels over here.

1334
00:53:11,187 --> 00:53:12,720
And this is a kind of regularizer

1335
00:53:12,720 --> 00:53:15,089
to prevent each of these [mumbling]

1336
00:53:15,089 --> 00:53:16,637
it regularizers a little bit to encourage

1337
00:53:16,637 --> 00:53:19,540
a little bit of extra special
smoothness in the image.

1338
00:53:19,540 --> 00:53:21,865
You also see they use L1
normalization of the gradients

1339
00:53:21,865 --> 00:53:23,627
that's kind of a useful trick sometimes

1340
00:53:23,627 --> 00:53:26,653
when doing this image generation problems.

1341
00:53:26,653 --> 00:53:29,908
You also see them clipping the
pixel values once in a while.

1342
00:53:29,908 --> 00:53:32,291
So again we talked about
images actually should be

1343
00:53:32,291 --> 00:53:33,843
between zero to 2.55

1344
00:53:33,843 --> 00:53:35,877
so this is a kind of
projected gradients decent

1345
00:53:35,877 --> 00:53:39,335
where we project on to the
space of actual valid images.

1346
00:53:39,335 --> 00:53:40,485
But now when we do all this

1347
00:53:40,485 --> 00:53:43,222
then we start, we might start
with some image of a sky

1348
00:53:43,222 --> 00:53:46,215
and then we get really
cool results like this.

1349
00:53:46,215 --> 00:53:47,871
So you can see that now

1350
00:53:47,871 --> 00:53:50,020
we've taken these tiny features on the sky

1351
00:53:50,020 --> 00:53:52,614
and they get amplified through
this, through this process.

1352
00:53:52,614 --> 00:53:54,631
And we can see things like this different

1353
00:53:54,631 --> 00:53:56,451
mutant animals start to pop up

1354
00:53:56,451 --> 00:53:59,007
or these kind of spiral shapes pop up.

1355
00:53:59,007 --> 00:54:01,576
Different kinds of houses and cars pop up.

1356
00:54:01,576 --> 00:54:04,296
So that's all, that's
all pretty interesting.

1357
00:54:04,296 --> 00:54:05,806
There's a couple patterns in particular

1358
00:54:05,806 --> 00:54:08,743
that pop up all the time
that people have named.

1359
00:54:08,743 --> 00:54:12,133
Right, so there's this Admiral
dog, that shows up allot.

1360
00:54:12,133 --> 00:54:14,151
There's the pig snail, the camel bird

1361
00:54:14,151 --> 00:54:16,033
this the dog fish.

1362
00:54:16,033 --> 00:54:18,712
Right, so these are
kind of interesting, but

1363
00:54:18,712 --> 00:54:20,988
actually this fact that
dog show up so much

1364
00:54:20,988 --> 00:54:22,771
in these visualization,
actually does tell us

1365
00:54:22,771 --> 00:54:26,249
something about the data on
which this network was trained.

1366
00:54:26,249 --> 00:54:27,769
Right, because this is a
network that was trained

1367
00:54:27,769 --> 00:54:28,996
for image net classification,

1368
00:54:28,996 --> 00:54:30,786
image that have thousand categories.

1369
00:54:30,786 --> 00:54:32,915
But 200 of those categories are dogs.

1370
00:54:32,915 --> 00:54:35,593
So, so it's kind of not
surprising in a sense

1371
00:54:35,593 --> 00:54:37,462
that when you do these
kind of visualizations

1372
00:54:37,462 --> 00:54:40,084
then network ends up hallucinating
a lot of dog like stuff

1373
00:54:40,084 --> 00:54:44,027
in the image often morphed
with other types of animals.

1374
00:54:44,027 --> 00:54:45,691
When you do this other
layers of the network

1375
00:54:45,691 --> 00:54:47,327
you get other types of results.

1376
00:54:47,327 --> 00:54:49,392
So here we're taking one
of these lower layers

1377
00:54:49,392 --> 00:54:51,594
in the network, the previous
example was relatively

1378
00:54:51,594 --> 00:54:52,708
high up in the network

1379
00:54:52,708 --> 00:54:55,482
and now again we have this
interpretation that lower layers

1380
00:54:55,482 --> 00:54:57,791
maybe computing edges and
swirls and stuff like that

1381
00:54:57,791 --> 00:55:00,166
and that's kind of borne out
when we running DeepDream

1382
00:55:00,166 --> 00:55:01,766
at a lower layer.

1383
00:55:01,766 --> 00:55:03,786
Or if you run this thing for a long time

1384
00:55:03,786 --> 00:55:05,840
and maybe add in some
multiscale processing

1385
00:55:05,840 --> 00:55:08,346
you can get some really,
really crazy images.

1386
00:55:08,346 --> 00:55:11,035
Right, so here they're doing a
kind of multiscale processing

1387
00:55:11,035 --> 00:55:12,599
where they start with a small image

1388
00:55:12,599 --> 00:55:14,631
run DeepDream on the small
image then make it bigger

1389
00:55:14,631 --> 00:55:16,289
and continue DeepDream on the larger image

1390
00:55:16,289 --> 00:55:18,781
and kind of repeat with
this multiscale processing

1391
00:55:18,781 --> 00:55:19,893
and then you can get,

1392
00:55:19,893 --> 00:55:22,479
and then maybe after you
complete the final scale

1393
00:55:22,479 --> 00:55:23,797
then you restart from the beginning

1394
00:55:23,797 --> 00:55:25,699
and you just go wild on this thing.

1395
00:55:25,699 --> 00:55:28,126
And you can get some really crazy images.

1396
00:55:28,126 --> 00:55:30,256
So these examples were all from networks

1397
00:55:30,256 --> 00:55:31,454
trained on image net

1398
00:55:31,454 --> 00:55:35,216
There's another data set from
MIT called MIT Places Data set

1399
00:55:35,216 --> 00:55:37,708
but instead of 1,000 categories of objects

1400
00:55:37,708 --> 00:55:40,224
instead it's 200 different types of scenes

1401
00:55:40,224 --> 00:55:42,663
like bedrooms and kitchens
like stuff like that.

1402
00:55:42,663 --> 00:55:45,202
And now if we repeat
this DeepDream procedure

1403
00:55:45,202 --> 00:55:48,472
using an network trained at MIT places.

1404
00:55:48,472 --> 00:55:50,868
We get some really cool
visualization as well.

1405
00:55:50,868 --> 00:55:53,251
So now instead of dogs,
slugs and admiral dogs

1406
00:55:53,251 --> 00:55:55,610
and that's kind of stuff,
instead we often get these

1407
00:55:55,610 --> 00:55:59,491
kind of roof shapes of these
kind of Japanese style building

1408
00:55:59,491 --> 00:56:02,104
or these different types of
bridges or mountain ranges.

1409
00:56:02,104 --> 00:56:05,288
They're like really, really
cool beautiful visualizations.

1410
00:56:05,288 --> 00:56:08,121
So the code for DeepDream is
online, released by Google

1411
00:56:08,121 --> 00:56:11,685
you can go check it out and
make your own beautiful pictures

1412
00:56:11,685 --> 00:56:13,517
So there's another kind of...

1413
00:56:13,517 --> 00:56:14,535
Sorry question?

1414
00:56:24,731 --> 00:56:28,252
So the question is, what
are taking gradient of?

1415
00:56:28,252 --> 00:56:31,819
So like I say, if you, because
like one over x squared

1416
00:56:31,819 --> 00:56:33,318
on the gradient of that is x.

1417
00:56:33,318 --> 00:56:36,678
So, if you send back
the volume of activation

1418
00:56:36,678 --> 00:56:38,368
as the gradient, that's equivalent to max,

1419
00:56:38,368 --> 00:56:41,082
that's equivalent to taking the
gradient with respect to the

1420
00:56:41,082 --> 00:56:42,952
like one over x squared some...

1421
00:56:42,952 --> 00:56:44,477
Some of the values.

1422
00:56:44,477 --> 00:56:46,707
So it's equivalent to maximizing the norm

1423
00:56:46,707 --> 00:56:49,665
of that of the features of that layer.

1424
00:56:49,665 --> 00:56:51,844
But in practice many implementation

1425
00:56:51,844 --> 00:56:53,118
you'll see not explicitly compute that

1426
00:56:53,118 --> 00:56:56,511
instead of send gradient back.

1427
00:56:56,511 --> 00:56:58,941
So another kind of useful,
another kind of useful thing

1428
00:56:58,941 --> 00:57:01,478
we can do is this concept
of feature inversion.

1429
00:57:01,478 --> 00:57:04,024
So this again gives us a
sense for what types of,

1430
00:57:04,024 --> 00:57:06,187
what types of elements
of the image are captured

1431
00:57:06,187 --> 00:57:07,687
at different layers of the network.

1432
00:57:07,687 --> 00:57:09,952
So what we're going to
do now is we're going to

1433
00:57:09,952 --> 00:57:12,220
take an image, run that
image through network

1434
00:57:12,220 --> 00:57:15,832
record the feature value
for one of those images

1435
00:57:15,832 --> 00:57:18,423
and now we're going to try
to reconstruct that image

1436
00:57:18,423 --> 00:57:20,283
from its feature representation.

1437
00:57:20,283 --> 00:57:22,198
And the question, and now

1438
00:57:22,198 --> 00:57:23,998
based on the how much, how much like

1439
00:57:23,998 --> 00:57:25,885
what that reconstructed image looks like

1440
00:57:25,885 --> 00:57:28,377
that'll give us some sense
for what type of information

1441
00:57:28,377 --> 00:57:31,074
about the image was captured
in that feature vector.

1442
00:57:31,074 --> 00:57:32,864
So again, we can do this
with gradient ascent

1443
00:57:32,864 --> 00:57:34,191
with some regularizer.

1444
00:57:34,191 --> 00:57:37,152
Where now rather than
maximizing some score

1445
00:57:37,152 --> 00:57:39,611
instead we want to minimize the distance

1446
00:57:39,611 --> 00:57:41,709
between this catch feature vector.

1447
00:57:41,709 --> 00:57:44,397
And between the computed
features of our generated image.

1448
00:57:44,397 --> 00:57:47,252
To try and again synthesize
a new image that matches

1449
00:57:47,252 --> 00:57:50,014
the feature back to
that we computed before.

1450
00:57:50,014 --> 00:57:53,453
And another kind of regularizer
that you frequently see here

1451
00:57:53,453 --> 00:57:55,048
is the total variation regularizer

1452
00:57:55,048 --> 00:57:56,856
that you also see on your homework.

1453
00:57:56,856 --> 00:57:59,118
So here with the total
variation regularizer

1454
00:57:59,118 --> 00:58:01,885
is panelizing differences
between adjacent pixels

1455
00:58:01,885 --> 00:58:04,569
on both of the left and
adjacent in left and right

1456
00:58:04,569 --> 00:58:05,954
and adjacent top to bottom.

1457
00:58:05,954 --> 00:58:07,970
To again try to encourage
special smoothness

1458
00:58:07,970 --> 00:58:09,956
in the generated image.

1459
00:58:09,956 --> 00:58:12,521
So now if we do this
idea of feature inversion

1460
00:58:12,521 --> 00:58:14,542
so this visualization here on the left

1461
00:58:14,542 --> 00:58:16,369
we're showing some original image.

1462
00:58:16,369 --> 00:58:18,294
The elephants or the fruits at the left.

1463
00:58:18,294 --> 00:58:19,802
And then we run that,

1464
00:58:19,802 --> 00:58:22,458
we run the image through a VGG-16 network.

1465
00:58:22,458 --> 00:58:25,512
Record the features of
that network at some layer

1466
00:58:25,512 --> 00:58:28,036
and then try to synthesize
a new image that matches

1467
00:58:28,036 --> 00:58:30,013
the recorded features of that layer.

1468
00:58:30,013 --> 00:58:32,514
And this is, this kind of
give us a sense for what

1469
00:58:32,514 --> 00:58:35,599
how much information is
stored in this images.

1470
00:58:35,599 --> 00:58:37,534
In these features of different layers.

1471
00:58:37,534 --> 00:58:39,900
So for example if we try
to reconstruct the image

1472
00:58:39,900 --> 00:58:43,849
based on the relu2_2 features
from VGC's, from VGG-16.

1473
00:58:43,849 --> 00:58:46,628
We see that the image gets
almost perfectly reconstructed.

1474
00:58:46,628 --> 00:58:48,372
Which means that we're
not really throwing away

1475
00:58:48,372 --> 00:58:52,664
much information about the raw
pixel values at that layer.

1476
00:58:52,664 --> 00:58:55,155
But as we move up into the
deeper parts of the network

1477
00:58:55,155 --> 00:58:58,593
and try to reconstruct
from relu4_3, relu5_1.

1478
00:58:58,593 --> 00:59:01,311
We see that our reconstructed image now,

1479
00:59:01,311 --> 00:59:03,435
we've kind of kept the general space,

1480
00:59:03,435 --> 00:59:05,488
the general spatial
structure of the image.

1481
00:59:05,488 --> 00:59:08,322
You can still tell that, that
it's a elephant or a banana

1482
00:59:08,322 --> 00:59:09,684
or a, or an apple.

1483
00:59:09,684 --> 00:59:11,675
But a lot of the low level details aren't

1484
00:59:11,675 --> 00:59:13,461
exactly what the pixel values were

1485
00:59:13,461 --> 00:59:14,833
and exactly what the colors were,

1486
00:59:14,833 --> 00:59:16,427
exactly what the textures were.

1487
00:59:16,427 --> 00:59:18,532
These are kind of low level details are

1488
00:59:18,532 --> 00:59:20,923
kind of lost at these higher
layers of this network.

1489
00:59:20,923 --> 00:59:22,366
So that gives us some sense that

1490
00:59:22,366 --> 00:59:24,756
maybe as we move up through
the flairs of the network

1491
00:59:24,756 --> 00:59:27,094
it's kind of throwing away
this low level information

1492
00:59:27,094 --> 00:59:29,153
about the exact pixels of the image

1493
00:59:29,153 --> 00:59:31,408
and instead is maybe trying
to keep around a little bit

1494
00:59:31,408 --> 00:59:33,888
more semantic information,
it's a little bit invariant

1495
00:59:33,888 --> 00:59:38,109
for small changes in color and
texture and things like that.

1496
00:59:38,109 --> 00:59:41,798
So we're building towards
a style transfer here

1497
00:59:41,798 --> 00:59:42,835
which is really cool.

1498
00:59:42,835 --> 00:59:45,392
So in addition to
understand style transfer,

1499
00:59:45,392 --> 00:59:47,185
in addition to feature inversion.

1500
00:59:47,185 --> 00:59:49,286
We also need to talk
about a related problem

1501
00:59:49,286 --> 00:59:51,029
called texture synthesis.

1502
00:59:51,029 --> 00:59:53,790
So in texture synthesis, this
is kind of an old problem

1503
00:59:53,790 --> 00:59:55,112
in computer graphics.

1504
00:59:55,112 --> 00:59:57,129
Here the idea is that
we're given some input

1505
00:59:57,129 --> 00:59:58,626
patch of texture.

1506
00:59:58,626 --> 01:00:00,465
Something like these little scales here

1507
01:00:00,465 --> 01:00:01,930
and now we want to build some model

1508
01:00:01,930 --> 01:00:05,792
and then generate a larger
piece of that same texture.

1509
01:00:05,792 --> 01:00:08,935
So for example, we might here
want to generate a large image

1510
01:00:08,935 --> 01:00:12,056
containing many scales that
kind of look like input.

1511
01:00:12,056 --> 01:00:15,986
And this is again a pretty old
problem in computer graphics.

1512
01:00:15,986 --> 01:00:18,551
There are nearest neighbor
approaches to textual synthesis

1513
01:00:18,551 --> 01:00:19,720
that work pretty well.

1514
01:00:19,720 --> 01:00:21,659
So, there's no neural networks here.

1515
01:00:21,659 --> 01:00:23,591
Instead, this kind of a simple algorithm

1516
01:00:23,591 --> 01:00:25,697
where we march through the generated image

1517
01:00:25,697 --> 01:00:27,792
one pixel at a time in scan line order.

1518
01:00:27,792 --> 01:00:28,931
And then copy...

1519
01:00:28,931 --> 01:00:32,000
And then look at a neighborhood
around the current pixel

1520
01:00:32,000 --> 01:00:34,742
based on the pixels that
we've already generated

1521
01:00:34,742 --> 01:00:38,229
and now compute a nearest
neighbor of that neighborhood

1522
01:00:38,229 --> 01:00:39,657
in the patches of the input image

1523
01:00:39,657 --> 01:00:41,934
and then copy over one
pixel from the input image.

1524
01:00:41,934 --> 01:00:43,968
So, maybe you don't need to
understand the details here

1525
01:00:43,968 --> 01:00:46,902
just the idea is that there's
a lot classical algorithms

1526
01:00:46,902 --> 01:00:48,889
for texture synthesis,
it's a pretty old problem

1527
01:00:48,889 --> 01:00:52,749
but you can do this without
neural networks basically.

1528
01:00:52,749 --> 01:00:54,598
And when you run this kind of

1529
01:00:54,598 --> 01:00:57,103
this kind of classical
texture synthesis algorithm

1530
01:00:57,103 --> 01:00:59,915
it actually works reasonably
well for simple textures.

1531
01:00:59,915 --> 01:01:02,117
But as we move to more complex textures

1532
01:01:02,117 --> 01:01:04,855
these kinds of simple methods
of maybe copying pixels

1533
01:01:04,855 --> 01:01:06,343
from the input patch directly

1534
01:01:06,343 --> 01:01:08,970
tend not to work so well.

1535
01:01:08,970 --> 01:01:11,857
So, in 2015, there was a really cool paper

1536
01:01:11,857 --> 01:01:14,270
that tried to apply
neural network features

1537
01:01:14,270 --> 01:01:16,494
to this problem of texture synthesis.

1538
01:01:16,494 --> 01:01:18,258
And ended up framing it as kind of

1539
01:01:18,258 --> 01:01:19,907
a gradient ascent procedure,

1540
01:01:19,907 --> 01:01:21,314
kind of similar to the feature map,

1541
01:01:21,314 --> 01:01:22,874
the various feature matching objectives

1542
01:01:22,874 --> 01:01:24,753
that we've seen already.

1543
01:01:24,753 --> 01:01:28,203
So, in order to perform
neural texture synthesis

1544
01:01:28,203 --> 01:01:30,558
they use this concept of a gram matrix.

1545
01:01:30,558 --> 01:01:31,708
So, what we're going to do,

1546
01:01:31,708 --> 01:01:34,416
is we're going to take our input texture

1547
01:01:34,416 --> 01:01:36,372
and in this case some pictures of rocks

1548
01:01:36,372 --> 01:01:37,830
and then take that input texture

1549
01:01:37,830 --> 01:01:40,351
and pass it through some
convolutional neural network

1550
01:01:40,351 --> 01:01:43,022
and pull out convolutional features

1551
01:01:43,022 --> 01:01:44,347
at some layer of the network.

1552
01:01:44,347 --> 01:01:47,536
So, maybe then this
convolutional feature volume

1553
01:01:47,536 --> 01:01:50,040
that we've talked about,
might be H by W by C

1554
01:01:50,040 --> 01:01:53,596
or sorry, C by H by W at
that layer of the network.

1555
01:01:53,596 --> 01:01:56,515
So, you can think of this
as an H by W spacial grid.

1556
01:01:56,515 --> 01:01:57,813
And at each point of the grid,

1557
01:01:57,813 --> 01:01:59,894
we have this C dimensional feature vector

1558
01:01:59,894 --> 01:02:02,318
describing the rough
appearance of that image

1559
01:02:02,318 --> 01:02:04,347
at that point.

1560
01:02:04,347 --> 01:02:06,431
And now, we're going to
use this activation map

1561
01:02:06,431 --> 01:02:10,179
to compute a descriptor of the
texture of this input image.

1562
01:02:10,179 --> 01:02:12,066
So, what we're going to do is take,

1563
01:02:12,066 --> 01:02:14,124
pick out two of these
different feature columns

1564
01:02:14,124 --> 01:02:15,294
in the input volume.

1565
01:02:15,294 --> 01:02:16,485
Each of these feature columns

1566
01:02:16,485 --> 01:02:18,318
will be a C dimensional vector.

1567
01:02:18,318 --> 01:02:21,239
And now take the outer product
between those two vectors

1568
01:02:21,239 --> 01:02:23,390
to give us a C by C matrix.

1569
01:02:23,390 --> 01:02:24,660
This C by C matrix now

1570
01:02:24,660 --> 01:02:26,393
tells us something about the co-occurrence

1571
01:02:26,393 --> 01:02:30,333
of the different features at
those two points in the image.

1572
01:02:30,333 --> 01:02:33,172
Right, so, if an element,
if like element IJ

1573
01:02:33,172 --> 01:02:35,023
in the C by C matrix is large

1574
01:02:35,023 --> 01:02:38,338
that means both elements I and
J of those two input vectors

1575
01:02:38,338 --> 01:02:40,218
were large and something like that.

1576
01:02:40,218 --> 01:02:43,098
So, this somehow captures
some second order statistics

1577
01:02:43,098 --> 01:02:46,477
about which features, in that feature map

1578
01:02:46,477 --> 01:02:49,367
tend to activate to together
at different spacial volumes...

1579
01:02:49,367 --> 01:02:51,572
At different spacial positions.

1580
01:02:51,572 --> 01:02:53,833
And now we're going to
repeat this procedure

1581
01:02:53,833 --> 01:02:55,911
using all different
pairs of feature vectors

1582
01:02:55,911 --> 01:02:58,071
from all different points
in this H by W grid.

1583
01:02:58,071 --> 01:02:59,386
Average them all out, and that gives us

1584
01:02:59,386 --> 01:03:01,664
our C by C gram matrix.

1585
01:03:01,664 --> 01:03:04,323
And this is then used a
descriptor to describe

1586
01:03:04,323 --> 01:03:06,323
kind of the texture of that input image.

1587
01:03:06,323 --> 01:03:08,308
So, what's interesting
about this gram matrix

1588
01:03:08,308 --> 01:03:11,018
is that it has now thrown
away all spacial information

1589
01:03:11,018 --> 01:03:13,623
that was in this feature volume.

1590
01:03:13,623 --> 01:03:16,144
Because we've averaged over
all pairs of feature vectors

1591
01:03:16,144 --> 01:03:17,545
at every point in the image.

1592
01:03:17,545 --> 01:03:19,753
Instead, it's just
capturing the second order

1593
01:03:19,753 --> 01:03:21,863
co-occurrence statistics between features.

1594
01:03:21,863 --> 01:03:25,364
And this ends up being a
nice descriptor for texture.

1595
01:03:25,364 --> 01:03:27,640
And by the way, this is
really efficient to compute.

1596
01:03:27,640 --> 01:03:31,922
So, if you have a C by H by
W three dimensional tensure

1597
01:03:31,922 --> 01:03:34,548
you can just reshape
it to see times H by W

1598
01:03:34,548 --> 01:03:36,858
and take that times its own transpose

1599
01:03:36,858 --> 01:03:38,180
and compute this all in one shot

1600
01:03:38,180 --> 01:03:39,682
so it's super efficient.

1601
01:03:39,682 --> 01:03:40,981
But you might be wondering why

1602
01:03:40,981 --> 01:03:42,916
you don't use an actual covariance matrix

1603
01:03:42,916 --> 01:03:45,417
or something like that instead
of this funny gram matrix

1604
01:03:45,417 --> 01:03:47,298
and the answer is that using covariance...

1605
01:03:47,298 --> 01:03:50,082
Using true covariance matrices also works

1606
01:03:50,082 --> 01:03:51,845
but it's a little bit
more expensive to compute.

1607
01:03:51,845 --> 01:03:52,908
So, in practice a lot of people

1608
01:03:52,908 --> 01:03:55,203
just use this gram matrix descriptor.

1609
01:03:55,203 --> 01:03:56,954
So then... Then there's this...

1610
01:03:56,954 --> 01:04:00,146
Now once we have this sort of
neural descriptor of texture

1611
01:04:00,146 --> 01:04:03,168
then we use a similar type
of gradient ascent procedure

1612
01:04:03,168 --> 01:04:05,693
to synthesize a new image
that matches the texture

1613
01:04:05,693 --> 01:04:06,916
of the original image.

1614
01:04:06,916 --> 01:04:09,540
So, now this looks kind of
like the feature reconstruction

1615
01:04:09,540 --> 01:04:10,913
that we saw a few slides ago.

1616
01:04:10,913 --> 01:04:14,052
But instead, I'm trying to
reconstruct the whole feature map

1617
01:04:14,052 --> 01:04:15,231
from the input image.

1618
01:04:15,231 --> 01:04:17,178
Instead, we're just going
to try and reconstruct

1619
01:04:17,178 --> 01:04:19,179
this gram matrix texture descriptor

1620
01:04:19,179 --> 01:04:20,883
of the input image instead.

1621
01:04:20,883 --> 01:04:23,077
So, in practice what this
looks like is that well...

1622
01:04:23,077 --> 01:04:24,495
You'll download some pretrained model,

1623
01:04:24,495 --> 01:04:25,969
like in feature inversion.

1624
01:04:25,969 --> 01:04:28,720
Often, people will use
the VGG networks for this.

1625
01:04:28,720 --> 01:04:31,580
You'll feed your... You'll
take your texture image,

1626
01:04:31,580 --> 01:04:33,008
feed it through the VGG network,

1627
01:04:33,008 --> 01:04:35,265
compute the gram matrix
and many different layers

1628
01:04:35,265 --> 01:04:38,553
of this network.

1629
01:04:38,553 --> 01:04:40,726
Then you'll initialize your new image

1630
01:04:40,726 --> 01:04:43,019
from some random initialization

1631
01:04:43,019 --> 01:04:45,427
and then it looks like
gradient ascent again.

1632
01:04:45,427 --> 01:04:47,414
Just like for these other
methods that we've seen.

1633
01:04:47,414 --> 01:04:48,734
So, you take that image, pass it through

1634
01:04:48,734 --> 01:04:50,414
the same VGG network,

1635
01:04:50,414 --> 01:04:52,530
Compute the gram matrix at various layers

1636
01:04:52,530 --> 01:04:53,703
and now compute loss

1637
01:04:53,703 --> 01:04:57,213
as the L2 norm between the gram matrices

1638
01:04:57,213 --> 01:05:00,833
of your input texture
and your generated image.

1639
01:05:00,833 --> 01:05:03,012
And then you back prop,
and compute pixel...

1640
01:05:03,012 --> 01:05:06,025
A gradient of the pixels
on your generated image.

1641
01:05:06,025 --> 01:05:07,325
And then make a gradient ascent step

1642
01:05:07,325 --> 01:05:09,273
to update the pixels of
the image a little bit.

1643
01:05:09,273 --> 01:05:11,517
And now, repeat this process many times,

1644
01:05:11,517 --> 01:05:13,259
go forward, compute your gram matrices,

1645
01:05:13,259 --> 01:05:14,538
compute your losses, back prop..

1646
01:05:14,538 --> 01:05:17,071
Gradient on the image and repeat.

1647
01:05:17,071 --> 01:05:19,342
And once you do this, eventually
you'll end up generating

1648
01:05:19,342 --> 01:05:22,702
a texture that matches your
input texture quite nicely.

1649
01:05:22,702 --> 01:05:25,776
So, this was all from Nip's 2015 paper

1650
01:05:25,776 --> 01:05:27,125
by a group in Germany.

1651
01:05:27,125 --> 01:05:30,022
And they had some really cool
results for texture synthesis.

1652
01:05:30,022 --> 01:05:31,133
So, here on the top,

1653
01:05:31,133 --> 01:05:33,531
we're showing four
different input textures.

1654
01:05:33,531 --> 01:05:36,362
And now, on the bottom, we're showing

1655
01:05:36,362 --> 01:05:38,562
doing this texture synthesis approach

1656
01:05:38,562 --> 01:05:41,133
by gram matrix matching.

1657
01:05:41,133 --> 01:05:43,739
Using, by computing the gram
matrix at different layers

1658
01:05:43,739 --> 01:05:45,681
at this pretrained convolutional network.

1659
01:05:45,681 --> 01:05:48,244
So, you can see that, if we
use these very low layers

1660
01:05:48,244 --> 01:05:49,471
in the convolutional network

1661
01:05:49,471 --> 01:05:51,273
then we kind of match the general...

1662
01:05:51,273 --> 01:05:53,743
We generally get splotches
of the right colors

1663
01:05:53,743 --> 01:05:55,364
but the overall spacial structure

1664
01:05:55,364 --> 01:05:56,965
doesn't get preserved so much.

1665
01:05:56,965 --> 01:06:00,401
And now, as we move to large
down further in the image

1666
01:06:00,401 --> 01:06:03,384
and you compute these gram
matrices at higher layers

1667
01:06:03,384 --> 01:06:05,825
you see that they tend to
reconstruct larger patterns

1668
01:06:05,825 --> 01:06:06,935
from the input image.

1669
01:06:06,935 --> 01:06:10,107
For example, these whole rocks
or these whole cranberries.

1670
01:06:10,107 --> 01:06:11,834
And now, this works pretty well

1671
01:06:11,834 --> 01:06:14,188
that now we can synthesize
these new images

1672
01:06:14,188 --> 01:06:16,323
that kind of match the
general spacial statistics

1673
01:06:16,323 --> 01:06:17,677
of your inputs.

1674
01:06:17,677 --> 01:06:19,418
But they are quite different pixel wise

1675
01:06:19,418 --> 01:06:21,445
from the actual input itself.

1676
01:06:21,445 --> 01:06:22,528
Question?

1677
01:06:28,481 --> 01:06:30,847
So, the question is, where
do we compute the loss?

1678
01:06:30,847 --> 01:06:33,236
And in practice, we
want to get good results

1679
01:06:33,236 --> 01:06:35,283
typically people will
compute gram matrices

1680
01:06:35,283 --> 01:06:36,421
at many different layers

1681
01:06:36,421 --> 01:06:38,684
and then the final loss
will be a sum of all those

1682
01:06:38,684 --> 01:06:40,285
potentially a weighted sum.

1683
01:06:40,285 --> 01:06:41,936
But I think for this visualization,

1684
01:06:41,936 --> 01:06:44,369
to try to pin point the
effect of the different layers

1685
01:06:44,369 --> 01:06:45,736
I think these were doing reconstruction

1686
01:06:45,736 --> 01:06:47,940
from just one layer.

1687
01:06:47,940 --> 01:06:49,353
So, now something really...

1688
01:06:49,353 --> 01:06:51,783
Then, then they had a
really brilliant idea

1689
01:06:51,783 --> 01:06:52,999
kind of after this paper

1690
01:06:52,999 --> 01:06:56,193
which is, what if we do this
texture synthesis approach

1691
01:06:56,193 --> 01:06:59,124
but instead of using an image
like rocks or cranberries

1692
01:06:59,124 --> 01:07:01,417
what if we set it equal
to a piece of artwork.

1693
01:07:01,417 --> 01:07:03,748
So then, for example, if you...

1694
01:07:03,748 --> 01:07:06,004
If you do the same texture
synthesis algorithm

1695
01:07:06,004 --> 01:07:09,067
by maximizing gram
matrices, but instead of...

1696
01:07:09,067 --> 01:07:10,333
But now we take, for example,

1697
01:07:10,333 --> 01:07:12,030
Vincent Van Gogh's Starry night

1698
01:07:12,030 --> 01:07:14,656
or the Muse by Picasso as our texture...

1699
01:07:14,656 --> 01:07:18,175
As our input texture,
and then run this same

1700
01:07:18,175 --> 01:07:19,759
texture synthesis algorithm.

1701
01:07:19,759 --> 01:07:21,727
Then we can see our generated images tend

1702
01:07:21,727 --> 01:07:23,602
to reconstruct interesting pieces

1703
01:07:23,602 --> 01:07:25,683
from those pieces of artwork.

1704
01:07:25,683 --> 01:07:27,951
And now, something really
interesting happens

1705
01:07:27,951 --> 01:07:30,815
when you combine this
idea of texture synthesis

1706
01:07:30,815 --> 01:07:32,157
by gram matrix matching

1707
01:07:32,157 --> 01:07:34,616
with feature inversion
by feature matching.

1708
01:07:34,616 --> 01:07:37,151
And then this brings us to
this really cool algorithm

1709
01:07:37,151 --> 01:07:38,988
called style transfer.

1710
01:07:38,988 --> 01:07:42,716
So, in style transfer, we're
going to take two images as input.

1711
01:07:42,716 --> 01:07:44,688
One, we're going to take a content image

1712
01:07:44,688 --> 01:07:47,285
that will guide like what
type of thing we want.

1713
01:07:47,285 --> 01:07:49,813
What we generally want
our output to look like.

1714
01:07:49,813 --> 01:07:51,504
Also, a style image that will tell us

1715
01:07:51,504 --> 01:07:53,220
what is the general texture or style

1716
01:07:53,220 --> 01:07:55,499
that we want our generated image to have

1717
01:07:55,499 --> 01:07:57,471
and then we will jointly
do feature recon...

1718
01:07:57,471 --> 01:07:59,062
We will generate a new image

1719
01:07:59,062 --> 01:08:01,400
by minimizing the feature
reconstruction loss

1720
01:08:01,400 --> 01:08:02,596
of the content image

1721
01:08:02,596 --> 01:08:05,661
and the gram matrix
loss of the style image.

1722
01:08:05,661 --> 01:08:07,064
And when we do these two things

1723
01:08:07,064 --> 01:08:08,984
we a get a really cool image that kind of

1724
01:08:08,984 --> 01:08:12,261
renders the content image
kind of in the artistic style

1725
01:08:12,261 --> 01:08:14,353
of the style image.

1726
01:08:14,353 --> 01:08:16,192
And now this is really cool.

1727
01:08:16,192 --> 01:08:18,317
And you can get these
really beautiful figures.

1728
01:08:18,317 --> 01:08:19,649
So again, what this kind of looks like

1729
01:08:19,649 --> 01:08:22,433
is that you'll take your style
image and your content image

1730
01:08:22,433 --> 01:08:25,328
pass them into your network
to compute your gram matrices

1731
01:08:25,328 --> 01:08:26,384
and your features.

1732
01:08:26,384 --> 01:08:28,129
Now, you'll initialize your output image

1733
01:08:28,129 --> 01:08:29,332
with some random noise.

1734
01:08:29,332 --> 01:08:30,937
Go forward, compute your losses

1735
01:08:30,938 --> 01:08:33,648
go backward, compute your
gradients on the image

1736
01:08:33,648 --> 01:08:35,242
and repeat this process over and over

1737
01:08:35,242 --> 01:08:38,265
doing gradient ascent on the
pixels of your generated image.

1738
01:08:38,265 --> 01:08:40,098
And after a few hundred iterations,

1739
01:08:40,099 --> 01:08:43,247
generally you'll get a beautiful image.

1740
01:08:43,247 --> 01:08:45,950
So, I have implementation of this online

1741
01:08:45,950 --> 01:08:47,853
on my Gethub, that a
lot of people are using.

1742
01:08:47,853 --> 01:08:48,965
And it's really cool.

1743
01:08:48,965 --> 01:08:50,952
So, you can, this is kind of...

1744
01:08:50,952 --> 01:08:52,144
Gives you a lot more control

1745
01:08:52,144 --> 01:08:54,609
over the generated image
as compared to DeepDream.

1746
01:08:54,609 --> 01:08:56,711
Right, so in DeepDream, you
don't have a lot of control

1747
01:08:56,711 --> 01:08:59,154
about exactly what types of
things are going to happen

1748
01:08:59,154 --> 01:09:00,544
coming out at the end.

1749
01:09:00,544 --> 01:09:02,207
You just kind of pick different
layers of the networks

1750
01:09:02,207 --> 01:09:04,133
maybe set different numbers of iterations

1751
01:09:04,133 --> 01:09:06,500
and then dog slugs pop up everywhere.

1752
01:09:06,500 --> 01:09:07,624
But with style transfer,

1753
01:09:07,624 --> 01:09:09,182
you get a lot more fine grain control

1754
01:09:09,182 --> 01:09:11,228
over what you want the
result to look like.

1755
01:09:11,228 --> 01:09:13,375
Right, by now, picking
different style images

1756
01:09:13,375 --> 01:09:14,910
with the same content image

1757
01:09:14,910 --> 01:09:17,729
you can generate whole
different types of results

1758
01:09:17,729 --> 01:09:19,099
which is really cool.

1759
01:09:19,099 --> 01:09:21,529
Also, you can play around with
the hyper parameters here.

1760
01:09:21,529 --> 01:09:23,355
Right, because we're doing
a joint reconstruct...

1761
01:09:23,356 --> 01:09:26,366
We're minimizing this
feature reconstruction loss

1762
01:09:26,366 --> 01:09:27,497
of the content image.

1763
01:09:27,497 --> 01:09:30,349
And this gram matrix reconstruction
loss of the style image.

1764
01:09:30,350 --> 01:09:31,968
If you trade off the constant,

1765
01:09:31,968 --> 01:09:34,346
the waiting between those
two terms and the loss.

1766
01:09:34,346 --> 01:09:36,112
Then you can get control
about how much we want

1767
01:09:36,113 --> 01:09:37,322
to match the content versus

1768
01:09:37,322 --> 01:09:39,469
how much we want to match the style.

1769
01:09:39,469 --> 01:09:41,647
There's a lot of other hyper
parameters you can play with.

1770
01:09:41,647 --> 01:09:43,992
For example, if you resize the style image

1771
01:09:43,992 --> 01:09:45,707
before you compute the gram matrix

1772
01:09:45,707 --> 01:09:47,840
that can give you some control

1773
01:09:47,840 --> 01:09:49,660
over what the scale of features are

1774
01:09:49,660 --> 01:09:51,162
that you want to reconstruct

1775
01:09:51,162 --> 01:09:52,344
from the style image.

1776
01:09:52,344 --> 01:09:53,420
So, you can see that here,

1777
01:09:53,420 --> 01:09:54,919
we've done this same reconstruction

1778
01:09:54,919 --> 01:09:57,314
the only difference is how
big was the style image

1779
01:09:57,314 --> 01:09:58,976
before we computed the gram matrix.

1780
01:09:58,976 --> 01:10:01,304
And this gives you another axis over

1781
01:10:01,304 --> 01:10:04,263
which you can control these things.

1782
01:10:04,263 --> 01:10:06,391
You can also actually do style transfer

1783
01:10:06,391 --> 01:10:07,670
with multiple style images

1784
01:10:07,670 --> 01:10:10,181
if you just match sort
of multiple gram matrices

1785
01:10:10,181 --> 01:10:11,508
at the same time.

1786
01:10:11,508 --> 01:10:13,431
And that's kind of a cool result.

1787
01:10:13,431 --> 01:10:15,699
We also saw this multi-scale process...

1788
01:10:15,699 --> 01:10:17,569
So, another cool thing you can do.

1789
01:10:17,569 --> 01:10:20,139
We talked about this multi-scale
processing for DeepDream

1790
01:10:20,139 --> 01:10:22,454
and saw how multi scale
processing in DeepDream

1791
01:10:22,454 --> 01:10:25,105
can give you some really
cool resolution results.

1792
01:10:25,105 --> 01:10:27,440
And you can do a similar type
of multi-scale processing

1793
01:10:27,440 --> 01:10:29,330
in style transfer as well.

1794
01:10:29,330 --> 01:10:32,432
So, then we can compute images like this.

1795
01:10:32,432 --> 01:10:36,506
That a super high resolution,
this is I think a 4k image

1796
01:10:36,506 --> 01:10:38,101
of our favorite school,

1797
01:10:38,101 --> 01:10:40,867
like rendered in the
style of Starry night.

1798
01:10:40,867 --> 01:10:42,652
But this is actually super
expensive to compute.

1799
01:10:42,652 --> 01:10:44,544
I think this one took four GPU's.

1800
01:10:44,544 --> 01:10:47,074
So, a little expensive.

1801
01:10:47,074 --> 01:10:49,253
We can also other style,
other style images.

1802
01:10:49,253 --> 01:10:50,531
And get some really cool results

1803
01:10:50,531 --> 01:10:51,800
from the same content image.

1804
01:10:51,800 --> 01:10:53,666
Again, at high resolution.

1805
01:10:53,666 --> 01:10:56,451
Another fun thing you can do is

1806
01:10:56,451 --> 01:10:59,129
you know, you can actually
do joint style transfer

1807
01:10:59,129 --> 01:11:01,168
and DeepDream at the same time.

1808
01:11:01,168 --> 01:11:03,919
So, now we'll have three
losses, the content loss

1809
01:11:03,919 --> 01:11:05,606
the style loss and this...

1810
01:11:05,606 --> 01:11:09,017
And this DeepDream loss that
tries to maximize the norm.

1811
01:11:09,017 --> 01:11:11,623
And get something like this.

1812
01:11:11,623 --> 01:11:12,766
So, now it's Van Gogh

1813
01:11:12,766 --> 01:11:14,286
with the dog slug's coming out everywhere.

1814
01:11:14,286 --> 01:11:15,858
[laughing]

1815
01:11:15,858 --> 01:11:18,466
So, that's really cool.

1816
01:11:18,466 --> 01:11:19,867
But there's kind of a problem

1817
01:11:19,867 --> 01:11:21,399
with this style transfer for algorithms

1818
01:11:21,399 --> 01:11:23,012
which is that they are pretty slow.

1819
01:11:23,012 --> 01:11:24,140
Right, you need to produce...

1820
01:11:24,140 --> 01:11:26,633
You need to compute a lot of
forward and backward passes

1821
01:11:26,633 --> 01:11:28,482
through your pretrained network

1822
01:11:28,482 --> 01:11:30,164
in order to complete these images.

1823
01:11:30,164 --> 01:11:32,489
And especially for these high
resolution results that we saw

1824
01:11:32,489 --> 01:11:33,770
in the previous slide.

1825
01:11:33,770 --> 01:11:36,160
Each forward and backward
pass of a 4k image

1826
01:11:36,160 --> 01:11:38,200
is going to take a lot of
compute and a lot of memory.

1827
01:11:38,200 --> 01:11:40,878
And if you need to do several
hundred of those iterations

1828
01:11:40,878 --> 01:11:42,569
generating these images could take many,

1829
01:11:42,569 --> 01:11:43,662
like tons of minutes

1830
01:11:43,662 --> 01:11:46,340
even on a powerful GPU.

1831
01:11:46,340 --> 01:11:48,371
So, it's really not so
practical to apply these things

1832
01:11:48,371 --> 01:11:50,320
in practice.

1833
01:11:50,320 --> 01:11:52,852
The solution is to now,
train another neural network

1834
01:11:52,852 --> 01:11:54,874
to do the style transfer for us.

1835
01:11:54,874 --> 01:11:57,536
So, I had a paper about this last year

1836
01:11:57,536 --> 01:12:00,129
and the idea is that we're
going to fix some style

1837
01:12:00,129 --> 01:12:01,615
that we care about at the beginning.

1838
01:12:01,615 --> 01:12:03,164
In this case, Starry night.

1839
01:12:03,164 --> 01:12:04,241
And now rather than running

1840
01:12:04,241 --> 01:12:05,988
a separate optimization procedure

1841
01:12:05,988 --> 01:12:08,034
for each image that we want to synthesize

1842
01:12:08,034 --> 01:12:10,783
instead we're going to train
a single feed forward network

1843
01:12:10,783 --> 01:12:12,978
that can input the content image

1844
01:12:12,978 --> 01:12:15,748
and then directly output
the stylized result.

1845
01:12:15,748 --> 01:12:17,433
And now the way that we train this network

1846
01:12:17,433 --> 01:12:20,106
is that we compute the same content

1847
01:12:20,106 --> 01:12:22,906
and style losses during training
of our feed forward network

1848
01:12:22,906 --> 01:12:25,491
and use that same gradient
to update the weights

1849
01:12:25,491 --> 01:12:26,848
of the feed forward network.

1850
01:12:26,848 --> 01:12:29,785
And now this thing takes
maybe a few hours to train

1851
01:12:29,785 --> 01:12:30,998
but once it's trained,

1852
01:12:30,998 --> 01:12:32,994
then in order to produce stylized images

1853
01:12:32,994 --> 01:12:34,586
you just need to do a single forward pass

1854
01:12:34,586 --> 01:12:36,148
through the trained network.

1855
01:12:36,148 --> 01:12:37,957
So, I have a code for this online

1856
01:12:37,957 --> 01:12:40,501
and you can see that it
ends up looking about...

1857
01:12:40,501 --> 01:12:43,513
Relatively comparable
quality in some cases

1858
01:12:43,513 --> 01:12:45,864
to this very slow optimization base method

1859
01:12:45,864 --> 01:12:47,101
but now it runs in real time

1860
01:12:47,101 --> 01:12:49,880
it's about a thousand times faster.

1861
01:12:49,880 --> 01:12:53,101
So, here you can see, this is
like a demo of it running live

1862
01:12:53,101 --> 01:12:54,990
off my webcam.

1863
01:12:54,990 --> 01:12:57,347
So, this is not running
live right now obviously,

1864
01:12:57,347 --> 01:12:59,523
but if you have a big GPU

1865
01:12:59,523 --> 01:13:01,528
you can easily run four different styles

1866
01:13:01,528 --> 01:13:03,391
in real time all simultaneously

1867
01:13:03,391 --> 01:13:05,476
because it's so efficient.

1868
01:13:05,476 --> 01:13:07,191
There was... There was
another group from Russia

1869
01:13:07,191 --> 01:13:08,569
that had a very similar out...

1870
01:13:08,569 --> 01:13:10,809
That had a very similar paper concurrently

1871
01:13:10,809 --> 01:13:12,650
and their results are about as good.

1872
01:13:12,650 --> 01:13:15,392
They also had this kind
of tweek on the algorithm.

1873
01:13:15,392 --> 01:13:19,140
So, this feed forward
network that we're training

1874
01:13:19,140 --> 01:13:20,872
ends up looking a lot like these...

1875
01:13:20,872 --> 01:13:22,962
These segmentation models that we saw.

1876
01:13:22,962 --> 01:13:25,450
So, these segmentation networks,

1877
01:13:25,450 --> 01:13:27,906
for semantic segmentation
we're doing down sampling

1878
01:13:27,906 --> 01:13:29,711
and then many, and then many layers

1879
01:13:29,711 --> 01:13:32,551
then some up sampling [mumbling]

1880
01:13:32,551 --> 01:13:35,654
With transposed convulsion in order

1881
01:13:35,654 --> 01:13:37,678
to down sample an up sample
to be more efficient.

1882
01:13:37,678 --> 01:13:39,735
The only difference is
that this final layer

1883
01:13:39,735 --> 01:13:41,547
produces a three channel output

1884
01:13:41,547 --> 01:13:45,244
for the RGB of that final image.

1885
01:13:45,244 --> 01:13:47,247
And inside this network,
we have batch normalization

1886
01:13:47,247 --> 01:13:48,540
in the various layers.

1887
01:13:48,540 --> 01:13:50,275
But in this paper, they introduce...

1888
01:13:50,275 --> 01:13:52,003
They swap out the batch normalization

1889
01:13:52,003 --> 01:13:53,693
for something else called
instance normalization

1890
01:13:53,693 --> 01:13:56,027
tends to give you much better results.

1891
01:13:56,027 --> 01:13:59,191
So, one drawback of these
types of methods is that

1892
01:13:59,191 --> 01:14:02,384
we're now training one new
style transfer network...

1893
01:14:02,384 --> 01:14:05,500
For every... For style
that we want to apply.

1894
01:14:05,500 --> 01:14:07,038
So that could be expensive

1895
01:14:07,038 --> 01:14:08,454
if now you need to keep a lot

1896
01:14:08,454 --> 01:14:10,433
of different trained networks around.

1897
01:14:10,433 --> 01:14:13,534
So, there was a paper from
Google that just came...

1898
01:14:13,534 --> 01:14:16,047
Pretty recently that addressed this

1899
01:14:16,047 --> 01:14:18,450
by using one feed forward trained network

1900
01:14:18,450 --> 01:14:21,178
to apply many different
styles to the input image.

1901
01:14:21,178 --> 01:14:22,884
So now, they can train one network

1902
01:14:22,884 --> 01:14:26,887
to apply many different
styles at test time

1903
01:14:26,887 --> 01:14:28,034
using one trained network.

1904
01:14:28,034 --> 01:14:30,839
So, here's it's going to
take the content images input

1905
01:14:30,839 --> 01:14:33,397
as well as the identity of
the style you want to apply

1906
01:14:33,397 --> 01:14:34,805
and then this is using one network

1907
01:14:34,805 --> 01:14:36,477
to apply many different types of styles.

1908
01:14:36,477 --> 01:14:39,365
And again, runs in real time.

1909
01:14:39,365 --> 01:14:42,346
That same algorithm can also
do this kind of style blending

1910
01:14:42,346 --> 01:14:44,442
in real time with one trained network.

1911
01:14:44,442 --> 01:14:45,935
So now, once you trained this network

1912
01:14:45,935 --> 01:14:47,453
on these four different styles

1913
01:14:47,453 --> 01:14:49,668
you can actually specify
a blend of these styles

1914
01:14:49,668 --> 01:14:52,458
to be applied at test
time which is really cool.

1915
01:14:52,458 --> 01:14:55,759
So, these kinds of real
time style transfer methods

1916
01:14:55,759 --> 01:14:58,552
are on various apps and
you can see these out

1917
01:14:58,552 --> 01:15:01,976
in practice a lot now these days.

1918
01:15:01,976 --> 01:15:04,071
So, kind of the summary
of what we've seen today

1919
01:15:04,071 --> 01:15:05,896
is that we've talked about
many different methods

1920
01:15:05,896 --> 01:15:08,113
for understanding CNN representations.

1921
01:15:08,113 --> 01:15:10,190
We've talked about some of
these activation based methods

1922
01:15:10,190 --> 01:15:12,254
like nearest neighbor,
dimensionality reduction,

1923
01:15:12,254 --> 01:15:14,220
maximal patches, occlusion images

1924
01:15:14,220 --> 01:15:16,676
to try to understand based
on the activation values

1925
01:15:16,676 --> 01:15:18,316
of what the features are looking for.

1926
01:15:18,316 --> 01:15:20,461
We also talked about a bunch
of gradient based methods

1927
01:15:20,461 --> 01:15:23,754
where you can use gradients
to synthesize new images

1928
01:15:23,754 --> 01:15:27,127
to understand your features
such as saliency maps

1929
01:15:27,127 --> 01:15:29,382
class visualizations, fooling images,

1930
01:15:29,382 --> 01:15:30,417
feature inversion.

1931
01:15:30,417 --> 01:15:31,620
And we also had fun by seeing

1932
01:15:31,620 --> 01:15:33,110
how a lot of these similar ideas

1933
01:15:33,110 --> 01:15:35,528
can be applied to things like
Style Transfer and DeepDream

1934
01:15:35,528 --> 01:15:37,997
to generate really cool images.

1935
01:15:37,997 --> 01:15:40,397
So, next time, we'll talk
about unsupervised learning

1936
01:15:40,397 --> 01:15:42,380
Autoencoders, Variational Autoencoders

1937
01:15:42,380 --> 01:15:43,917
and generative adversarial networks

1938
01:15:43,917 --> 00:00:00,000
so that should be a fun lecture.

